{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathyanarayanajammala/GenAI/blob/main/M1_AST1_Predictive_AI_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmBawJ8kUNl8"
      },
      "source": [
        "# Generative AI and Prompt Engineering\n",
        "## A program by IISc and TalentSprint\n",
        "### Assignment: 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2WYpEkJUNl_"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQOkgatUUNl_"
      },
      "source": [
        "At the end of the experiment, you will be able to\n",
        "\n",
        "* Get introduced to PyTorch and it's usage\n",
        "* Apply neural networks to regression problems\n",
        "* Learn about image classification tasks\n",
        "* Understand & build Dense Neural Network  model class in PyTorch\n",
        "* Train and test the model in PyTorch\n",
        "* Understand the concept of transfer learning and pre-trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DS2llW6UNmA"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8o5njJtUNmA"
      },
      "source": [
        "Artificial Neural Network (ANN) is a Machine Learning model inspired by the networks of biological neurons found in our brains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V89Kc7-QUNmC"
      },
      "source": [
        "#### Artificial Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKdTy3JEUNmC"
      },
      "source": [
        "Modeled after human brain activity, artificial neurons are digital constructs that simulate the behavior of biological neurons in some ways. The first computational model of an (artificial) neuron was proposed by Warren McCulloch (neuroscientist) and Walter Pitts (logician) in 1943.\n",
        "\n",
        "As shown below, it may be divided into 2 parts. The first part, g takes an input, performs aggregation, and based on the aggregated value, the second part, f, makes a decision. Understand further through an example 'Watch a football game' in this [article](https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1).\n",
        "\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/369/1*fDHlg9iNo0LLK4czQqqO9A.png\" width= 320px/>\n",
        "</center>\n",
        "\n",
        "<br><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_H_B9QgPWxS"
      },
      "source": [
        "### Install the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3YTjTHHJZEd",
        "outputId": "17877c6a-cc01-4044-fd49-52cf5fd3d10a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZLYIcdJffR4"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2416497\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY9tgfHgffSY"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"6301058763\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Hlj81lsuffSZ",
        "outputId": "239c64a8-c4c7-463e-ad39-0db763f03547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2416497&recordId=44\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M1_AST1_Predictive_AI_A\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://genai-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psn-z1duUNmA"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULpxRHv-UNmA"
      },
      "outputs": [],
      "source": [
        "# Importing torch packages\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "import torchvision.models as models\n",
        "\n",
        "# Importing other packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVboGuzaOt6w"
      },
      "source": [
        "* Import pytorch, the deep learning library which will be used in the assignment, and torchvision, which provides the dataset and data transformations.\n",
        "\n",
        "* import torch.nn (pytorch’s neural network library), torch.nn.functional (includes non-linear functions like ReLu and sigmoid) and torch.optim for implementing various optimization algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  1.Introduction to PyTorch\n",
        "\n",
        "PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab (FAIR). It provides a flexible and intuitive platform for building, training, and deploying deep learning models. PyTorch is widely used in both academia and industry due to its dynamic computation graph, ease of use, and robust support for GPU acceleration.\n",
        "\n",
        "### Overview of PyTorch\n",
        "\n",
        "1. **Dynamic Computation Graphs (Define-by-Run)**:\n",
        "   - PyTorch uses dynamic computation graphs, which are constructed on-the-fly as operations are performed. This is in contrast to static computation graphs used by frameworks like TensorFlow (prior to TensorFlow 2.0).\n",
        "   - The dynamic nature allows for more flexibility and ease of debugging, as the graph is built dynamically during runtime.\n",
        "\n",
        "2. **Tensor Library**:\n",
        "   - PyTorch's tensor library is similar to NumPy but with strong GPU acceleration.\n",
        "   - Tensors are the fundamental building blocks in PyTorch, representing multi-dimensional arrays.\n",
        "\n",
        "3. **Autograd**:\n",
        "   - PyTorch's automatic differentiation engine, Autograd, enables automatic computation of gradients. This is essential for training neural networks using gradient-based optimization algorithms.\n",
        "   - Autograd records operations performed on tensors to create a computation graph and compute gradients during backpropagation.\n",
        "\n",
        "4. **Modules and nn.Module**:\n",
        "   - PyTorch's `nn` module provides a high-level interface for building neural networks. The `nn.Module` class is a base class for all neural network modules.\n",
        "   - Layers, loss functions, and optimizers are provided within the `nn` module, facilitating the construction of complex neural networks.\n",
        "\n",
        "5. **Extensive Ecosystem**:\n",
        "   - PyTorch has a rich ecosystem, including libraries like torchvision (for computer vision), torchaudio (for audio processing), and torchtext (for natural language processing).\n",
        "   - Integration with other tools such as TensorBoard for visualization and ONNX for model export enhances its utility.\n",
        "\n",
        "### Advantages of Using PyTorch for Deep Learning\n",
        "\n",
        "1. **Ease of Use and Flexibility**:\n",
        "   - PyTorch's dynamic computation graph and Pythonic nature make it intuitive and easy to use, especially for researchers and developers who prefer interactive and imperative programming.\n",
        "   - The ability to modify the computation graph on-the-fly allows for more flexibility in model design and experimentation.\n",
        "\n",
        "2. **Strong GPU Support**:\n",
        "   - PyTorch provides seamless integration with CUDA, enabling efficient utilization of GPU resources for accelerated computation.\n",
        "   - Multi-GPU support and distributed training capabilities allow for scaling up models and training on large datasets.\n",
        "\n",
        "3. **Community and Support**:\n",
        "   - PyTorch has a large and active community, contributing to a wealth of tutorials, code examples, and pre-trained models.\n",
        "   - Continuous updates and improvements from both the open-source community and Facebook AI Research ensure that PyTorch stays at the cutting edge of deep learning technology.\n",
        "\n",
        "4. **Interoperability**:\n",
        "   - PyTorch's support for ONNX (Open Neural Network Exchange) allows for easy model export and interoperability with other frameworks and platforms.\n",
        "   - This makes it convenient to deploy PyTorch models in various production environments.\n",
        "\n",
        "5. **Debugging and Prototyping**:\n",
        "   - The dynamic nature of PyTorch makes it easier to debug and prototype models. Developers can use standard Python debugging tools to inspect and modify the computation graph.\n",
        "   - The interactive experience provided by Jupyter notebooks and other IDEs is enhanced by PyTorch’s immediate execution model.\n",
        "\n",
        "6. **Research and Innovation**:\n",
        "   - PyTorch's flexibility and ease of use make it a popular choice among researchers for developing and testing new ideas.\n",
        "   - Many cutting-edge research papers and innovations in the field of deep learning are implemented and shared using PyTorch."
      ],
      "metadata": {
        "id": "WBgekybKSf0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print(x)"
      ],
      "metadata": {
        "id": "hniKPTeBYaoG",
        "outputId": "40b9527f-3ad6-4d44-842a-3f52cab162eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor operations\n",
        "y = torch.ones(2, 2)\n",
        "print(y)\n",
        "z = x + y\n",
        "print(z)"
      ],
      "metadata": {
        "id": "WYBhG8sfYbid",
        "outputId": "a2160bb1-e986-4382-ee42-34b954f7c376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[2., 3.],\n",
            "        [4., 5.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Autograd\n",
        "# Requires_grad flag for automatic differentiation\n",
        "x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True)\n",
        "y = torch.tensor([[5., 6.], [7., 8.]], requires_grad=True)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "A_7mEXOUYez2",
        "outputId": "2774c3ba-dc83-4bdc-f22d-a5791f6c4c95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True)\n",
            "tensor([[5., 6.],\n",
            "        [7., 8.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computation\n",
        "z = x + y\n",
        "print(z)"
      ],
      "metadata": {
        "id": "A_zDe-vuYoch",
        "outputId": "55a59480-5b0f-47c2-b017-deae384cca37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing gradients\n",
        "t = torch.sum(z)\n",
        "t.backward()\n",
        "\n",
        "# Accessing gradients\n",
        "# YOUR CODE HERE print gradients"
      ],
      "metadata": {
        "id": "SMkzGeGCYtwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement Dense Neural Network using PyTorch"
      ],
      "metadata": {
        "id": "jrc9n3W7Fac6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghlEu96VUNmD"
      },
      "source": [
        "### The Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBkkBAD8UNmD"
      },
      "source": [
        "The Perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron (shown in the figure below) called a **Neurons**. The inputs and the output are numbers (instead of binary on/off values), and each input connection is associated with a weight. The Neurons computes a weighted sum of its inputs $$(z = w_1 x_1 + w_2 x_2 + ⋯ + w_n x_n = x^⊺ w)$$, then applies a step function to that sum and outputs the result: $$h_w(x) = step(z)$$, where $z = x^⊺ w$.\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://www.oreilly.com/api/v2/epubs/9781492037354/files/assets/mlst_1004.png\" width= 400px/>\n",
        "</center>\n",
        "\n",
        "$\\hspace{10cm} \\text {Threshold logic unit}$\n",
        "<br><br>\n",
        "The most common step function used in Perceptrons is the Heaviside step function. Sometimes the sign function is used instead.\n",
        "\n",
        "$$heaviside (z) = \\begin{equation}\n",
        "\\left\\{\n",
        "  \\begin{aligned}\n",
        "    &0&  if\\ \\  z < 0\\\\\n",
        "    &1&  if\\ \\  z \\ge 0\\\\\n",
        "  \\end{aligned}\n",
        "  \\right.\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "$$sgn (z) = \\begin{equation}\n",
        "\\left\\{\n",
        "  \\begin{aligned}\n",
        "    &-1&  if\\ \\  z < 0\\\\\n",
        "    &0&  if\\ \\  z = 0\\\\\n",
        "    &1&  if\\ \\  z > 0\\\\\n",
        "  \\end{aligned}\n",
        "  \\right.\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "A single Neuron can be used for simple linear binary classification. It computes a linear combination of the inputs, and if the result exceeds a threshold, it outputs the positive class. Otherwise, it outputs the negative class.\n",
        "\n",
        "\n",
        "\n",
        "The decision boundary of each output neuron is linear, so Perceptrons are incapable of learning complex patterns (just like Logistic Regression classifiers). However, if the training instances are linearly separable, Rosenblatt demonstrated that this algorithm would converge to a solution. This is called the Perceptron convergence theorem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Univariate Linear Regression"
      ],
      "metadata": {
        "id": "-1IyIAmWDHbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAIAAAAqGSU5AAAgAElEQVR4Ae2dCXwWxf3/J4TkSUIwB4SbPEGkCIIRqxCkBRULCJQU61Ev4vGngpRCvYJYCQkS8UcLaBEVBCxqsQW5DEdIkEOOqmggCQg5CBIISKIkcgaSZ//K1HHZfXaefZ5n99nj+TwvXzg7Ozvz/b5n2Q8z891ZIuAHAiAAAiAAAqYhQExjCQwBARAAARAAAQGyhJsABEAABEDARAQgSybqDJgCAiAAAiAAWcI9AAIgAAIgYCICkCUTdQZMAQEQAAEQgCzhHgABEAABEDARAciSiToDpoAACIAACECWcA+AAAiAAAiYiABkyUSdAVNAAARAAAQgS7gHQEBHAoSQjIwMHRtA1SBgOwKQJdt1adA7VFhY+Pvf/z4xMdHhcLRr1+6OO+547bXXjKLijyw5nU5y+RcSEhITE9OjR4/Ro0f/97//9cqX6dOnr1y50qtLfCu8b9++jIyMiooK3y7HVSDACECWGAok7EBgx44d4eHh11xzzbRp0xYsWDBlypRBgwZ17tzZKN/8lKUbbrjh3cu/efPmjR8/vk2bNoSQv/zlL+rdadasWVpamvryPpdctmwZIWTz5s0+14ALQYASgCzhTrAVgaFDhyYkJJw6dUrs1TfffCM+DGTaT1kaNmyY2Npz58797ne/I4TMmzdPnM9JQ5Y4cHDKnAQgS+bsF1jlI4GuXbveeuutnIsXLVp02223JSQkhIeHd+vWTfJ8dzqdw4YN27x58y9/+cuIiIgePXrQf/5/+OGHPXr0cDgcN95445dffsnqT0tLa9asWXl5+aBBg6Kiotq2bZuZmelyuVgBiSwdPXr00UcfbdWqVXh4ePfu3RcuXMhKyhPUGEn+6dOn4+Pj27dvz1qZOXNm37594+PjIyIibrzxxmXLlrFL6Bwg+5MOmw4fPjx27Nhf/OIXERER8fHxd999t3jm7eLFi1OnTr3mmmscDkd8fHy/fv02btzIKvzqq69+//vfx8XFORyOX/7yl6tXr6anFi9ezFqhCQybGDQkvCUAWfKWGMqbmsCgQYOaN29eVFSkZOXNN9/8yCOPzJ49+x//+MegQYMIIXPnzmWFnU5n165d27ZtO3Xq1NmzZ7dv3z46Ovq9995LTEyccfkXExNzzTXXNDY20kvS0tIiIiK6dOny8MMPz507d/jw4YSQF198kVUolqUTJ0506NChY8eOWVlZb7zxxogRIwghs2fPZoUlCbeyJAjC448/TggpLi6m5Tt06PDkk0/OnTt31qxZvXv3JoTk5OTQU++++67D4fj1r39NZwJ37twpCMKyZcuSk5OnTJkyf/78yZMnx8XFOZ3Os2fP0ksmT54cEhIyevToBQsW/P3vf7///vtnzJhBTxUXF8fExHTv3v2VV16ZO3du//79Q0JCVqxYIQhCeXn5n//8Z0LI5MmTaVsnTpygV+FPEPCWAGTJW2Iob2oCGzduDL3869u373PPPZebm3vx4kWxxefOnRMfDh48+Oqrr2Y5NMqAPr4FQcjNzSWEREZGfv3117TMW2+9JV5BSUtLI4SMHz+ennW5XMOGDQsPD6+urqY5Yll6/PHH27ZtW1NTw5r7wx/+EBMTIzGJnVWSpdmzZxNC2EhFfPnFixd79Ohx++23s0rkk3ji8oIg7Nq1ixCyZMkSeklycrJk5pBVNXDgwJ49e164cIHmuFyuW265pUuXLvQQa0sMFBJ+EoAs+QkQl5uOwGeffTZy5MioqCg6m5SQkMCe4GJba2trq6urs7OzCSG1tbX0lNPp7N69OytWW1tLCBE/pvfs2UMIYZNvVJYOHjzILlm/fj0hZOnSpTSHyZLL5YqNjf3jH/9YLfrRua/t27ezy8UJJVlasGABIeS9994TFxYE4bvvvquurh47dmxsbCw7JZcldurixYs1NTXV1dWxsbETJ06k+QMGDEhKSiopKWHFaOLbb78NCQmZNm2ayPzqzMxMQsjRo0fpIEws2JLLcQgC6glAltSzQkkrEaivr//ss8+ef/75iIiIsLCwH8KXqfXbt28fOHAgEy0qXWww5HQ6hwwZIvaTEDJmzBiWU1FRQQj529/+RnPS0tKaNGly6dIlVqC8vJwQ8vLLL9McJkvffPONZPWFHdJ5MFYDSyjJkmS09NFHH/Xp08fhcLAKQ0JCWCVyWTp37tyLL77YoUOHkJAQdsmjjz5KL9m6dWtsbCwhpEePHs8888zevXtp/qeffsoKSxJ0sQ2jJcYcCT8JQJb8BIjLzU6AjkimTp0qCEJZWZnD4UhOTn7zzTfXrl2bl5f3l7/8hRDC1vzlSkAIGTduHHOSytLMmTNpjnpZOn78OCHkoYceypP9lAIF5cbQRunaEhXabdu2hYSEDBgwYOHChevWrcvLy3vggQd+0EJmsFyWHn/88SZNmjz11FPLli3buHFjXl5eixYtxEHk33777aJFi/7whz/ExsaGhoYuWLCAzfU988wzMvPzvv/+e4yWGHAk/Cfw8+3rf12oAQRMSKCoqIgQ8sQTTwiCQMcZbGwkCMLkyZP9lCVCiJpJvIaGhubNm99///3qEbmVJRqJ17FjRxqJN2HChMjISLbeIwiCRJaio6PFkvMDhJiYGDY2EgTh/PnzoaGhkjLUyNOnT/fq1at9+/aCINDR3vPPP69k//LlyzGJpwQH+V4RgCx5hQuFzU7g448/ZpHT1NZXXnmFEDJr1ixBEF577TVCyOHDh+mp2traH4Lu/JclSchDWFjYyZMnaRNsEk8QhEceeSQ8PLzoyihBVlJOVi5L7L2lN998k5Z/6qmnoqKiWBxdRUUFnZ9ktbVu3To1NZUd/gAhPj7+kUceYTn/93//9wMBJkviiAxBEO65556WLVvSwrfeemt8fHxVVRW7VhAEZj9dVAvMjhJiA5C2HwHIkv36NKg9uu666zp16vTUU0/Nnz9/7ty5DzzwQGhoaFJSEn3B9sCBA+Hh4T179pw7d+6MGTM6d+6cnJzspyzRAPFRo0a9/vrrNEB88uTJrA/EsnTixAmn0xkVFTVhwoS33nrr5Zdfvueee+Li4lhhScLpdLJdHt544w22y8PTTz/NSm7atIkQ8utf//qNN97IzMxs1arV9ddfL57EGzp0aLNmzf7+978vXbqUblw0atSo0NBQasMjjzzSoUMH8SReq1at7r333ldeeWXBggVPPPFESEgIE919+/bFxcW1aNFi0qRJ8+fPnzZt2tChQ6+//npqzPHjx0NDQ1NSUt55552lS5cqzUwyy5EAASUCkCUlMsi3JIH169c/9thj1157bXR0NN2FaPz48eJH5Jo1a66//vqIiIikpKRXXnll0aJFfsqS+HXa1q1bZ2RksLeaBEEQyxKdChs3blzHjh3DwsLatGkzcODA+fPnK4EW74l31VVXXXfddaNHj/70008l5RcuXNilSxeHw3HttdcuXrw4IyNDLEsHDhzo379/ZGQkGxKdOnXq0UcfbdmyZXR09ODBgw8cOOB0Otlo6aWXXurdu3dsbGxkZOS11147ffp0cYR9eXn5qFGj2rRpExYW1r59++HDhy9fvpzZs2DBgquvvjo0NBSzeYwJEj4QgCz5AA2XgMD/CNBdHoADBEBAQwKQJQ1hoqqgIwBZCrouh8P6E4As6c8YLdiXAGTJvn0LzwwjAFkyDD0atgEByJINOhEumI0AZMlsPQJ7QAAEQCCoCUCWgrr74TwIgAAImI0AZMlsPQJ7QAAEQCCoCVhGlhobGysrK2tra+vwAwEQAAEQsDKB2trayspK8Rt+Yh22jCxVVlZK9i3GIQiAAAiAgHUJVFZWitWIpS0jS/TLN5WVlVb+JwJsBwEQAAEQqKPDDPadMyZINGEZWaqrqyOE1NXVSRzAIQiAAAiAgLUI8J/nkCVr9SasBQEQAAHLE4AsWb4L4QAIgAAI2IkAZMlOvQlfQAAEQMDyBIJClhoaGs4H008psNLydyscAAEQCAICNpcll8tVVVW1P8h+Bw4cqK+vD4K7Fy6CAAjYkIDNZYlqUk1Nzblz54JkvHT27NnS0tLDhw9Lvg5uw5sXLoEACNiRgJ1lqaGhYf/+/TU1NXbsOJ5PtbW1+/fvF382lFca50AABEDATATsLEvnz5/fv3//uXPnzAQ8ELacO3du//7958+fD0RjaAMEQAAENCVgf1kKwqcz1eMgdFzTvxqoDARAwBgCkCVjuOvaKmRJV7yoHARAgBFoaHTtLKtZVXB0Z1lNQ6OL5fuTgCz5Q8+k10KWTNoxMAsE7EVgfVFVSna+Mz2H/peSnb++qMp/FyFL/jNUVUNaWhrdyrdp06atWrW64447Fi5c6PEFo8WLF8fExKhqQFQIsiSCgSQIgIAuBNYXVSX9JEhUlpLSc5LSc/xXJsiStMP0GJMKgpCWljZkyJDjx48fPXr0iy++mD59enR09J133nnp0iWpBaJjyJIIBpIgAAJmIdDQ6BKPk9iAKSk9JyU738/ZPMjSFd2s05iUylJqaqq4sU2bNhFCFixYIAjC3//+9x49ekRFRXXo0GHs2LGnT58WBGHz5s3ib6VkZGQIgrBkyZJf/vKX0dHRrVu3vv/++7/55htxnTSN0ZKcCXJAAAQ0JLCzrIZJkTyxs8yv13IgSz/3lH5jUreyJAhCcnLynXfeKQjC7NmzP/7444qKik2bNnXt2nXs2LGCINTX18+ZM+eqq646fvlHtWrhwoXr1q0rLy/ftWtX37596eU/+3A5BVmSAMEhCICAtgRWFRyVqxHLWVVw1J/mIEv/o6frmFRJlu67775u3bpJ+m/ZsmUtWrSgmfxJvM8//5wQQuVKXAlkSUwDaRAAAc0JYLTkGalbdfXq6awrZSVZuvfee7t37y4IQl5e3u23396uXbvo6OiIiAhCyNmzZwVBkMvS7t27hw8f3rFjx+jo6KioKELIvn37JIC8clxyLQ5BAARAwCMB+u94SciD83LIA9aW/kfPf1nSdUyqJEs9e/YcNmxYRUWFw+GYOHHirl27Dh48uHDhQkLIqVOn5LJ05syZFi1aPPDAA9u2bfvqq69yc3MJIQUFBZJ7CLIkAYJDEAABzQnQVQ+xMiES7wrI/stS4EdLNORh0aJFy5cvDwsLY8Hi06ZNY7L0/vvvR0dHM1d3795NCDly5AjNeffddyFLDA4SIAACASagU4yY2+c5c83aH033atCg65iUjpbkAeLDhw9vaGjYs2cPIWTOnDnl5eVLlixp3749k6UdO3YQQvLz86urq8+ePXvy5Mnw8PBnn322vLx89erVv/jFLyBL7GZFAgRAIPAE9HijBrL0cz/qNyalssRep01ISLjjjjsWLVrERkizZs1q27ZtZGTk4MGDlyxZwmRJEIQxY8a0aNGCEEIDxP/1r38lJSU5HI6+ffuuWbMGsvRz/yEFAiBgCwKQpSu6Uacx6RVt6H/g1TBRf3PQAgiAAAh4QQCyJIWlx5hU2obOx5AlnQGjehAAAR0JQJZ0hGtU1ZAlo8ijXRAAAf8JQJb8Z2i6GiBLpusSGAQCIKCaAGRJNSrrFIQsWaevYCkIgICUgP1lCR9Nl/Y5jkEABEDAxATsLEsNDQ379++vqfFrL1sT952iabW1tfv377948aJiCZwAARAAAbMSsLMsCYJQVVVFlencuXPng+N39uzZ0tLSw4cPu1zafMDYrLcu7AIBELAnAZvLksvlosq0P5h+Bw4cqK+vt+cNC69AAATsTsDmskS7r6GhIThGSv/zkm0eYfe7F/6BAAjYkEBQyJIN+w0ugQAIgIDRBHTafACyZHTHon0QAAEQsCAB/bZqgyxZ8HaAySAAAiBgKAG6sTX7Sjr9AGBSes6cvJJVBUd3ltU0NPoecgVZMrRv0TgIgAAImImAmnk5+hkgsSbJ0ynZ+euLqnzzDLLkGzdcBQIgAAJ2I6ByXo7/0VQqUf58qRayZLcbC/6AAAiAgEcC8lGR0rycfNCzquCofHgkz0lKz0nJzvdhNg+y5LH7UAAEQAAEbEVAPipau/dYSna+SmlRM1piVe0s83qfHciSre42OAMCIAACfAJuR0VMRdwmJNJC15aS0nPcFpZkrio4yrdHfhayJGeCHBAAARCwJwE10QoSXXGm58ilZX1RlbyY2xyJpKnBCllSQwllQAAEQMAOBLyaf2MyI5cWNbKEtaU6QkhdXZ0dbhz4AAIgAAL6EFAZrcAEya20qBlyIRJP4A/69Olf1AoCIAACFiPgcbQkXjFSkhaPlTgvx+DJQ/hUwuI/z4nKWgwvxnfDcPNgAAiAAAiYgQAnWiE5M3ft3ipxPJ7SK7H8IdeLq4osvMvDvHnzevbs2fzyLyUlZd26dbTbzp8//+STT8bHxzdr1uyuu+46ceKEx+6ELHlEhAIgAAIgIAgCZ1lofVGV/H0mOTT+aEm+ECWvgZ/Df57rO1pas2bN2rVrS0pKDh48OHny5LCwsOLiYkEQxowZ07Fjx02bNu3evTslJeWWW27h+yAImMTzSAgFQAAEQOBHAg2NruTMXLZ6xBJul5HEyJhibS+p7jM9XzzdRyvxWIO4Nk7aSFmSmBUXF/f222/X1taGhYUtW7aMnv3qq68IIbt27ZIUlhzy3ZAUxiEIgAAIBC0B38Y6kjdwqbCJlUlpIcoHzvznub6jJWZuQ0PD0qVLw8PD9+3bt2nTJkLIqVOn2NnExMRZs2axQ7cJvhtuL0EmCIAACAQhAf7KkPwVJTrvJ1Ygul+4Mz1HPOpSWojygTD/ea67LBUWFjZr1iw0NDQmJmbt2rWCILz//vvh4eFiT26++ebnnntOnEPTFy5cqPvpV1lZiQBxOSLkgAAIgICEAH+0tL20emdZjfjjFErh4EnpOX2m520vrRYXlrTl26HBslRfX19aWrp79+5Jkya1bNly37596mUpIyODXPnDe0u+3QS4CgRAIHgIKAXjJaXn3JCZ22d6HlttogMgvoz5H+AgJ2+wLIkNGjhw4B//+Ef1k3gYLYnpIQ0CIAACKgnQbfHE83LiNJMlulyUuaaY5cgTbif9VJqhVMxEsnTbbbelpaXRkIfly5dTiw8cOICQB6XOQz4IgAAI+EZAEsKQkp0vXihi8pOUnnNj1kZ2KE/YbbQ0adKkrVu3VlRUFBYWTpo0KSQkZOPGjTRAPDEx8eOPP969e3ffyz+P3Pnq6vFyFAABEACBYCPAAr53ltVsL6mWSw7L6ZWVKx9OaRUOLsfOf57rG/Lw2GOPOZ3O8PDwhISEgQMHUk0SBIG+ThsXFxcVFTVy5Mjjx4/L7Zbk8N2QFMYhCIAACICAmAA/PC9rTTGd0GNCpWE4uNgMmuY/z/WVJbk1Pufw3fC5WlwIAiAAAsFAwGNcg3zSz+ct7zzy5D/PIUseAaIACIAACFieACc8j334XDzp58On0NUzgiypZ4WSIAACIGBbAm7D8354OUm/UZESSsiSEhnkgwAIgIBeBAI28vDKgUDO1HEMgyxx4OAUCIAACGhPwCRPf7eOmUEvIUtuuwaZIAACIKALATpXxkLa6P5y/s+VmUFOtOIFWdKKJOoBARAAAQ8EOPvLscgCpSo4wmPm4ZeSO5x8yBIHDk6BAAiAgJYEPMZhKzXGER6dhl9KlgQgH7IUAMhoAgRAAAR+JMB/a1VpfzmO8Pgz/DJtl0CWTNs1MAwEQMBuBHwYLfGFh79pkB4b1gWgSyBLAYCMJkAABEDgRwJq3lqVkOIr2cwNX4mjJyRppeGXpAmzHUKWzNYjsAcEQMDOBLx9a5U/7zdzwwGJFIkPMVoy8k7iq6uRlqFtEAABELiSACd+4cqCPx7xR0vbS6tTsvMDub233ELNc/jPc+yJpzlwVAgCIAACP87mSb5NrgTF47yft8MvpYbMkw9ZMk9fwBIQAAEQcEPAo/B4Nfxy04DJsiBLJusQmAMCIAACMgIehUf98EtWt+kyIEum6xIYBAIgAAJyAnYSHrl34hzIkpgG0iAAAiAAAgYTgCwZ3AFoHgRAAARAQEwAsiSmgTQIgAAIgIDBBCBLBncAmgcBEAABEBATgCyJaSANAiAAAiBgMAHIksEdgOZBAARAAATEBCBLYhpIgwAIgAAIGEwAsmRwB6B5EAABEAABMQHIkpgG0iAAAiAAAgYTgCwZ3AFoHgRAAARAQEwAsiSmgTQIgAAIgIDBBCBLBncAmgcBELAQAf83pvO/Bgvh8s1UyJJv3HAVCIBA0BHwuI23RyL+1+CxCRsUgCzZoBPhAgiAgO4E6EePxJ8kT0rPSUrPWV9UpbJt/2tQ2ZDVi0GWrN6DsB8EQEB3AvWXGntl5Yo1iaaT0nNSsvMbGl0eLaAfmfWnBo9N2KYAZMk2XQlHQAAEdCGwvqiqV9ZGuaKwnJ1lNR4b3llWw8rLE2pq8NiEbQpAlmzTlXAEBEBAewLymTe5qKwqOOqx4VUFR+UXshw1NXhswjYFIEu26Uo4AgIgoDEBpZk3Jic0oWaswx8tvb2tXM1MoMbumbU6yJJZewZ2gQAIGE2AryXOyyEPXq0tJaXnSCSNHaZk56uPnjAajL7tQ5b05YvaQQAErEuAP/NGZUmlljQ0uubklTARkie8jeuzLlWPlkOWPCJCARAAgSAlwB8t9crKValJkteV5JpEc9TH9dm7PyBL9u5feAcCIOA7Abq25HbmrVfWxvpLjWqqVhM0IRYqNStVatq1bhnIknX7DpaDAAjoToCKilyZkjNVDZVUBk2IZQlReZAl3W9rNAACIGBpAuuLqpIzpe/S0qWgtXurdpbVrCo4urOsxm0oHX8aUKxGLI3REmTJ0n9fYDwIgIDuBBoaXX2m5zHZECc6Tfo5ss5tKJ3HoAlxbVhbon0JWdL9nkYDIAACliagcsTjNpRO5bU0qM+rHfYsjZRvPGSJzwdnQQAEgp2A+hGPfLijFDSRlJ7zw+pUn+n5bLTkdrAVnOiNlKXs7OybbropOjo6ISEhNTX1wIEDrA8GDBhARL8nnniCnXKb4Lvh9hJkggAIgIAaAupHPFRjJItD8qAJNq7Ct5fc8uc/z4nba7TKHDx48OLFi4uLi/fs2TN06NDExMQzZ87QygcMGDB69OjjP/3q6ur4jfLd4F+LsyAAAiDAIaA04mEDHUlCHkoneW8JAyMObUEQ+M9zfWVJbNnJkycJIVu3bqWZAwYMmDBhgrgAP813g38tzoIACIAAn4B8xCORIvGhZLREa8bAiE9YfJb/PA+cLJWWlhJCioqKqHEDBgxo2bJlixYtrrvuukmTJp09e1ZsNE1fuHCh7qdfZWUlIcTjoEpeCXJAAARAQA0ByYhHHIMn1qTkqbnbS6vdBouraQVlzDJaamxsHDZsWL9+/ViXvPXWWxs2bCgsLHzvvffat28/cuRIdoolMjIyRMtPPyYhSwwOEiAAApoTEI941u49RpeIxJrE0pim8we+KUZLY8aMcTqdlZWVbj3ZtGkTIaSsrExyFqMlCRAcggAIBJKAZPzENAnR3n72gvGyNG7cuA4dOhw6dEjJkzNnzhBCNmzYoFTA46CPcyFOgQAI2I+AeFij63xaQ6Nre0l18lTpHhBeffPCfvz99MhIWXK5XOPGjWvXrl1JSQnHje3btxNC9u7dyynDd4NzIU6BAAjYjIBkEKP3fBo/fNxt+IPNgGvuDv95rm/Iw9ixY2NiYrZs2fJTHPjxc+fOCYJQVlaWlZW1e/fuioqK1atXX3311f379+d7zneDfy3OggAI2IaAfLtu9pKQTj7yX7aVB4vrZIadquU/z/WVJUnAAiFk8eLFgiAcOXKkf//+8fHxDofjmmuuefbZZz3GMvDdsFOHwRcQAAElAkrbdbvdfIG/xapSE/J8jJbkTPzM4T/P9ZUlP00XX853Q1wSaRAAAbsSUKkQ2s7yKb1sK9dCu2LX3C/+8xyypDlwVAgCIKAXATXzaXrM8slfttV75lAvguaoF7Jkjn6AFSAAAn4T8DhaUj/L560t2o7AvG3dZuUhSzbrULgDAsFLwON8mkfd8oddwKLS/THSEtdClizRTTASBEBAFQH+fJqaWT5VzaCQngQgS3rSRd0gAAIBJ8CZT9N1tBRwR23bIGTJtl0Lx0AgaAkozad5nOULWmKmchyyZKrugDEgAALuCSgpjfvSyrn8WT7l63AmcAQgS4FjjZZAAAQoAW81Rmleztt6aOtKtaF3TEIAsmSSjoAZIBAUBBoaXXPyDor3NvW4Z53Sm0bZa/elZOezfbs91iPm65ueiWtAWj8CkCX92KJmEACBKwisL6pKzpRuts1/81TpTSOmRizBr+cKO3BgbgKQJXP3D6wDAbsQkA96xIqSkp3v9gsU/Ng5VgNNYL8fe9wskCV79CO8AAFTE1Az6HH7DQj+m0YSWaKHtB5M05n6huAaB1ni4sFJEAABLQioGfS4/QaEmgsl4rSq4CiCGrToNMPqgCwZhh4Ng0DwEFAz6HE7WlJ600giReLDOXklSek54hwsO1nrToMsWau/YC0IWJKAx0GP0tqSIAjyN43EkiNJ95me12f6z+F57CyWnSx030CWLNRZMBUErErA46BnfVEVxzfJpBwTG3liTt5BeSbLcTsg47SLU4YQgCwZgh2NgkDQEVAa9CRn5vI1iZKiIQwvripiGiNPZK0p5s8Wul2+CrqeML3DkCXTdxEMBAG7EJAMepIzc+fklcjjwjlBdPzJwJ1lNR4L2IWlnf2ALNm5d+EbCJiNAEdyqKkS6ZLs3aA0GciWjjwWMBsQ2CMnAFmSM0EOCIBA4AiIhWrt3iqPQXTyyUBJoJ3HAoHzDS35RACy5BM2XAQCIKAFAcnYqNOkKwK76eoRGwmxBiVXSUZUNHjP5+3yWCtIGEUAsmQUebQLAsFOgA5r5JELbnMkQXTiMZZ8dUoQBI8Fgp2+if2HLJm4c2AaCNiXAF0EcqtAbjOz1hTbFwY8u4IAZM5KYPgAACAASURBVOkKHDgAARAIDAF+yJxbZVITRx4Y49GKrgQgS7riReUgAALuCfBfMHIrS5ydINy3gVxrEoAsWbPfYDUIWJyAD6MlZ3qOZIXJ4gxgvnsCkCX3XJALAiCgK4GGRlevLOknAd0OksSZ2KZB104xSeWQJZN0BMwAgaAjkLWmWCw5atIYLQXDXQJZCoZeho8goDsBGpC94sujb28rX/FF5c6yGrdx22I7vJrHk7+9JK4KaTsRgCzZqTfhCwgYQ0Dyfisd98jfcpUYp7RRkHzYJNnHQVIPDm1GALJksw6FOyAQaAKct2KT0nP4Ud3yjYLkmuRMz7lB3S7jgfYc7elDALKkD1fUCgLBQcDjW7Eeo7rdjrQk4tRnep7HKcHg4B0UXkKWgqKb4SQIqCHgw4Y9ataHPMYp0HZnbjggUSPxocdK1DiIMpYgAFmyRDfBSBDQnYBk1OJxZYgapOatWJVR3fyqVFaiOyY0oD8ByJL+jNECCJiegHx9SGWUgSajJYqHXxVGS6a/iTQzELKkGUpUBAIWJaC0PqQmJttjNJ3HtSUGTakqNWawSpCwAQHIkg06ES6AgF8EfB6m0DWhTOW3Yj1G4knslgfmqRy0SerBoaUJQJYs3X0wHgQ0IMBf1FnxRaXbNiRrUfIv+KlcnZJULqnWt0okdeLQWgQgS9bqL1gLAtoT4I+WemVtlL97JF+LolFzU1YV/nXlj/+9va28/lKjb7b6EBDoW0O4ypwEIEvm7BdYBQKBI6C0qEOVRj6NprQW5UzPEY+ZMNAJXBfaqyXIkr36E96AgE8ElEY/TJnEkQv80RV72UiuZz6ZhouCjgBkKei6HA6DgFsC64uq+F+aYCHa/LUoJkvO9BwE0blFjUw+AcgSnw/OgkAQEVjx5VGxqEjS7IVWlaMldjnTsyBCCVf9IGCkLGVnZ990003R0dEJCQmpqakHDhxgjpw/f/7JJ5+Mj49v1qzZXXfddeLECXbKbYLvhttLkAkCICAhwNcbpi78tSimRizB9EzSHA5BwC0B/vOcuL1Gq8zBgwcvXry4uLh4z549Q4cOTUxMPHPmDK18zJgxHTt23LRp0+7du1NSUm655RZ+o3w3+NfiLAiAACWgpDfyuTj5C0ZMhOQJpmfgDAJqCPCf5/rKkti+kydPEkK2bt0qCEJtbW1YWNiyZctoga+++ooQsmvXLnF5SZrvhqQwDkEABJQIyPVGKXJB8oKROAaPKZNcz5TaRT4IMAL853ngZKm0tJQQUlRUJAjCpk2bCCGnTp1iViYmJs6aNYsd0sSFCxfqfvpVVlYSQurq6iRlcAgCQUVAkzd+JHrDifMWN7d2bxUVMLEmebvLQ1B1FpxVImAKWWpsbBw2bFi/fv2ole+//354eLjY4ptvvvm5554T5/yQzsjIIFf+IEsSRDgMKgLq5cQjFrHeqP/QkYYGeLQQBWxMwBSyNGbMGKfTWVn5vz1OVMoSRks2vi/hmrcE5C8eKU2+eVuzV+V90zOvmkBh2xMwXpbGjRvXoUOHQ4cOMdYqJ/FYeUEQ+G6ISyINAvYjoLTtQgCWdqBD9rudDPeI/zzXd23J5XKNGzeuXbt2JSUlYhA05GH58uU088CBAwh5EPNBGgQkBFQGdkuukh96qzGYtZMzRI7/BIyUpbFjx8bExGzZsuX4T79z585Rl8aMGZOYmPjxxx/v3r277+Uf31W+G/xrcRYErE6Av+2CyteGvNUYk0wbWr3vYL+cAP95ru9o6cp4hR+PFi9eTE2kr9PGxcVFRUWNHDny+PHjctPFOXw3xCWRBgH7EeCPlraXVnt02VuNMXDa0KMvKGB1AvznuVpZ+vjjj40FwXfDWNvQOgjoTUDpNVgaq91nep78yxRik3zQGL4Q4v1ZMV6kvSXAf56rlaXw8PCrr7562rRpR44c8dYCTcrz3dCkCVQCAmYmIH8NVv37Qz5ojCbThmbmCdsMJMB/nquVperq6lmzZiUnJzdt2nTQoEH//ve/6+vrA+kV341AWoK2QMAoAuuLqvpMz2dqJE7wQ/I8aow8FMIHJTMKC9q1HAH+81ytLDG3v/jiiz/96U8tLv/Gjx+/Z88edkrXBN8NXZtG5SBgHgLbS6rFaiRJK82t8TVmTl5JSvbPakc3fVCaNuTrn3lAwRIzE+A/z72WJUEQjh07lpGR4XA4mjVrFhoa+qtf/aq4uFhvBHw39G4d9YOASQh4HPe4tZOjMcmZuUnpOWJ5Y2/pyqcN2Sm3rSATBFQS4D/PvZClixcvLlu27M4772zatGlKSsqCBQvOnDlTUVHx4IMPduvWTaU1Phfju+FztbgQBKxFgD/uURotCYLgVmOc6TnJmbliTaJpNiTyNqbcWjBhrVEE+M9ztbJEJ+7i4+MnTJhAt1tl/hw/fjwkJIQd6pTgu6FTo6gWBMxGgDPuEX/13K3Zco2Zk3dQrkksh4qcfNnJbeXIBAH1BPjPc7WydPvtt//rX/+6cOGCvOFLly5t2bJFnq9tDt8NbdtCbSBgZgJuxz0qd/JuaHRtL6meueGrmRsObC+tVvmxWjPTgG1WJMB/nquSpYsXLz766KPiTe0CD4LvRuDtQYsgYCAB+biH/94SM1VyYa8sNzN4ktESuxYJENCKAP95rkqWBEG46qqrIEtadQnqAQH/Cfgwt0aHWUx1OAm2tuS/nagBBOQEtJGlUaNGyT/TJ29Mvxy+G/q1i5pBwB4ElDZ6oOIkDsZDuJ09etzMXvCf52pHS9OmTYuNjf3973+fnZ39qugXMM/5bgTMDDQEAhYlwA/h65W1kQ2eOB+rtajvMNtsBPjPc7WylOTu16lTp4B5y3cjYGagIRCwKAH+C08rvqjcWVazquDozrIa9R+rtSgKmG04Af7zXK0smdwNw82DASDAIeDDOhCnNt9O8UdLnBeefGsOV4EAhwBkiQMHp0BAdwKS4DejpsjW7q3qNOmK3RzYqpLHF550Z4QGgoyAZrJUWVn5+uuvp6en/0X0CxhMvhsBMwMNgYBXBOTBb4YEFMjNYCtJKl948sprFAYBPgH+81ztJF5+fn5UVFSPHj2aNm16ww03xMbGxsTE3Hbbbfy2NTzLd0PDhlAVCGhFQCn4LcDh10pmONNzOk3KWbv3mFb+oh4QUEmA/zxXK0s333zzlClTBEGIjo4uLy8/ffr0iBEj5s2bp9II/4vx3fC/ftQAApoTMMlyjknM0BwvKrQuAf7zXK0sRUdHl5WVCYIQGxtL9wvfs2eP0+kMGBe+GwEzAw2BgHoC/OC3VQVH1VflVUlJhIVRZnhlMwoHFQH+81ytLLVu3Xr//v2CIHTr1m316tWCIOzZs6dZs2YBQ8l3I2BmoCEQUE/AkGGKPMJCzX6s6p1CSRDwnwD/ea5WllJTU+fPny8IwtNPP33NNde89NJLN95448CBA/23T2UNfDdUVoJiIBBIAv7s9u2bnfLQBrp9g/yjSs70nAAvcfnmEa6yJQH+81ytLJWXl+/du1cQhDNnzjzxxBM9e/a86667Dh8+HDBkfDcCZgYaAgGvCFCdCMzWPkqhDUmXP6pEIwDFAXiIwfOqK1FYQwL857laWdLQIN+q4rvhW524CgQCQEA+q6Zyt29vbePPGbr9Mrq3TaA8CGhCgP88hyxpAhmVgACPgCQGgVfUj3MeQxsCY4YfHuDSYCHglyzFxsbGcX8Bo8h3I2BmoCEQMJYAR1rm5JWwOTp5AtsLGdtxaF1MgP889zBaesfTT9ySrmm+G7o2jcpBwCQEOPOB8mAHpkwIbTBJ98EMRoD/PPcgS6wWwxN8Nww3DwaAgN4E5MLD9jFSCnZgyqTTapbeLqN+uxLgP8+9lqXz58/XiX4Bo8Z3I2BmoCEQMISAkvDQkdD2kmqmQPLEnLyDhtiMRkFAiQD/ea5Wls6cOTNu3LiEhIQmV/6UWtU8n++G5s2hQhDgrOJ4BUeTevhRdjM3fCVXI5aj33YSXnFAYRBgBPjPc7Wy9OSTT3br1m358uWRkZGLFi2aNm1ahw4d3nvvPdaM3gm+G3q3jvqDjQBnFYehUKM3auphFXIS/Ci7mRsOMBGSJxDswAGLU4YQ4D/P1cpSx44dN2/eLAhC8+bNS0tLBUFYsmTJnXfeGTCX+G4EzAw0FAwE3K7iONNzMtcUs4+3qtEbt/X49hIrf7S0vbQ6JTtf/NIuFScEOwTD7WpFH/nPc7Wy1KxZs6+//loQhPbt23/66aeCIBw6dAh74lnxhoDNfAJKqzhsFJKSnZ+9dp9EA1j0AatcqR7fpILWJmlUvIEQlUBxAblJzDYkQMBYAtrIUs+ePbds2SIIwsCBA59++mlBEF599dX27dsHzDe+GwEzAw3ZngB/XMLESZ6Q6A2/Hh8m1jwKj5oBnO27Dw5aggD/ea52tDRr1qxXX31VEIS8vLyIiAiHw9GkSZM5c+YEDAHfjYCZgYZsT4C/iiNXI0kO0xt+Pb6FIXgUHjXLXbbvQThofgL857laWRL7efjw4Q8//JDu3CrO1zXNd0PXplF5UBHgj3IkIiQ/ZHrDr4epl7dsITzeEkN5ExLgP889y9LOnTs/+ugj5tg///nPpKSkhISE0aNHX7hwgeXrneC7oXfrqD94CDQ0upIzc+V6ozKH6Y3H1aDgQQpPQUBCgP889yxLQ4YMmTFjBq20sLCwadOm/+///b9Zs2a1adMmIyND0ph+h3w39GsXNQcbAX9kKSU7v6HRxYh5XA1iJZEAgaAiwH+ee5alNm3afP755xTZ5MmT+/XrR9P/+c9/unXrFjCUfDcCZgYasj0B/uQbf8yUvXafhI/H1SBJeRyCQDAQ4D/PPcuSw+E4cuQIJdWvX7+XXnqJpisqKqKjowNGkO9GwMxAQ7YnwA9V4MuSZLREWWE1yPb3DBz0lgD/ee5ZlhITE7du3SoIQn19fWRkZH5+PrWgsLAwLi7OW2t8Ls93w+dqcSEISAh4HC31yuKtPLG1JUm1OAQBEGAE+M9zz7I0ZsyYvn37btu27amnnmrRokV9fT2t+r333rvppptYM3on+G7o3TrqDx4CSqEKzsufHt9eUr3iy6OcMROLxAseYvAUBLwlwH+ee5al6urqX//61yEhIc2bN1+xYgVr/vbbb588eTI71DvBd0Pv1lF/UBHghyrwh1MYLQXVrQJnfSPAf557liXaam1tbUNDg9iCb7/9lo2cxPk6pflu6NQoqg1aApxQBaXhlGSXh6BFB8dBwCMB/vNcrSx5bMZtga1btw4fPrxt27aEkJUrV7IyaWlpRPQbPHgwO6WU4LuhdBXyQcBnApxQBf5wyucWcSEIBAkB/vNcX1lat27dCy+8sGLFCrksDRky5PhPv++++85jZ/Dd8Hg5CoCAtgT4w6mdZTWrCo6y7ca1bRq1gYDVCfCf5/rKEmMnl6XU1FR2Vk2C74aaGlAGBLQl4HY4xZErbVtHbSBgXQL857lhshQTE5OQkPCLX/xizJgxNTU1Hvny3fB4OQqAQAAI0Mk9cZwevi4RAOxownIE+M9zY2Rp6dKlq1evLiwsXLlyZbdu3W6++WZJPAWlfOHChbqffpWVlYSQuro6y3UADDYVAbdDHE0spKEQYk1i6RuzNtZfatSkFVQCAjYgYEZZEmMtLy8nhLC3dMWnMjIyRIERPyYhS2I+SHtLQNcZNn7geK+s3PVFVd4ajPIgYEsCZpclQRBatmz55ptvyuljtCRnghyfCeg9w+Zx1yLfPpfus7+4EARMS8DsslRZWRkSErJ69Wo+Qb4b/GtxFgSUZtg0fNmIP1oSf+Ac3QECQU6A/zzXd23p9OnTBZd/hJBZs2YVFBR8/fXXp0+ffuaZZ3bt2lVRUZGfn3/jjTd26dLF46eb+G4EeR/DfY8E+JqhydYMSq/ZshUmmtCkLY/+ogAImJkA/3muryxt3rxZsjiUlpZ27ty5QYMGJSQkhIWFOZ3O0aNHnzhxwiNBvhseL0eBICfAn2HTaiM7+TyhRJOc6TlatRXkHQr3LU2A/zzXV5Y0BMd3Q8OGUJVtCIiD7raXVMsVguX4NoIR18++/re+qKpX1kZWszzhW1u26RQ4AgKCIPCf55Al3CT2JCAJuuszPT85MzcpPUeiEz6vLUnqT8nOZ4F29Zca3X78wue27NlD8CqICUCWgrjzg9V1+WQaEySWoDEIvkXHua1fXBUtoElbwdqH8NvOBCBLdu5d+CYnwAm6uyEzt8/0PDZgEg9x5PUo5XDqF3+dljOcUqoZ+SAQJAQgS0HS0XDzfwT4QXfbS6v93EeVX7946cjt4hP6CQRAALKEeyC4COgddKd3/cHVW/A2KAlAloKy24PYafWjGd8g6V2/b1bhKhCwEAHIkoU6C6ZqQEDptVatAuH0rl8DBKgCBMxNALJk7v6BdToQWLu3isU10IS2H5hAoJ0OnYYqg4gAZCmIOhuuNjS65uSVJE/NlciSb0F3HJ4ItOPAwSkQ4BOALPH54Kx9CKwvqkrOlAoS1ae1e49p7icC7TRHigqDhABkKUg6OtjdXF8knbhjAyatVpWCHTH8BwGNCECWNAKJakxMQOkVV6ZMzvQc8RtFJnYFpoGA/QlAluzfx/CQH7RNxQlbd+M+AQGTEIAsmaQjYIaOBPivuFJZwmhJxw5A1SDgDQHIkje0UNaaBDyOlsS71VnTRVgNAvYhAFmyT1/CEyUCSq+40nGSeG9vpRqQDwIgEDACkKWAoUZDmhHwIfZa/oor1aQfdg1nX0LSzD5UBAIg4AcByJIf8HCpEQR8flNVcmHy1Nw5eQfZd2ONcAVtggAIuCEAWXIDBVmmJeDxC3t8y30YZvErxFkQAAHNCUCWNEeKCvUioPT6Ed6H1Ys46gUBIwhAloygjjZ9IsAPqEOEt09QcREImI4AZMl0XQKDlAhkrSmmcQpu/8T7sErckA8C1iIAWbJWfwWvtQ2Nrl5Z7jdapSqF0VLw3hzw3F4EIEv26k9ze+NPxAF/Bu/GrI2IqTN358M6EFBLALKklhTK+UlAEp/t7SeO+BsIZa4p9tM8XA4CIGASApAlk3SEzc3gB3arGUXxR0uYwbP5DQT3gokAZCmYetsgX/mB3Wv3VqVk57MoBqVRFGcDIexoZ1DHolkQ0IUAZEkXrKhUTIA/0GGCRBNJ6TlKm9TJNxDiFBYbgDQIgICFCECWLNRZVjWVvywkkSXnZVlSGgD5uUBlVYKwGwSCiQBkKZh62yBfvRotMZVSWi5SsxBlkKNoFgRAQAMCkCUNIKIKPgHOshATIXkCr8fyqeIsCNiVAGTJrj1rLr/cLgvJpUicozRaEgQBAyZz9S6sAQFNCUCWNMWJypQJyJeF1u49lpKdn5SeI1Yj/tqSIAjyevDBJGXqOAMC1iMAWbJen1nXYvkox+0oSikSj2qSRMYQjGfd+wGWg4BbApAlt1iQqQsBuSx5Nfrhv/+EzYd06TNUCgIBJwBZCjjyYG2QM/nmVq7knPgRfZy1KHlVyAEBEDAtAciSabvGVobxNx9S6Sr//SdE7qnEiGIgYHICkCWTd5AdzNNq8g2jJTvcDfABBDwRgCx5IoTzfhPQSk6U3n/CR9P97iJUAAImIgBZMlFnGG6KyjUeb+3UcPLN28g9b01FeRAAAcMJQJYM7wKzGMAJSfDTRK1GS9QM/ez0001cDgIgoAkByJImGC1fiSYhCUoUNJ9802lUp2Q/8kEABAJJALIUSNombUurkASOe5h848DBKRAAATEBI2Vp69atw4cPb9u2LSFk5cqVzCyXy/Xiiy+2adMmIiJi4MCBJSUl7JRSgu+G0lXIpwS0nWRToorJNyUyyAcBEBAT4D/Pibio5ul169a98MILK1askMjSjBkzYmJiVq1atXfv3hEjRnTq1On8+fP81vlu8K/FWQ1DEvgwMfnG54OzIAACgiDwn+f6yhLrALEsuVyuNm3azJw5k56tra11OBxLly5lhd0m+G64vQSZjEBgRkusOTUJCJgaSigDArYkwH+eGyBL5eXlhJCCggKGu3///n/+85/ZIUtcuHCh7qdfZWUlIaSuro6dRUI9Ac1DEtQ3LSlJ1ShrTXGvrFy2rXhKdj72CJeAwiEI2JiA6WRpx44dhJCqqioG/Z577rn33nvZIUtkZGSQK3+QJQbH24QZQhIki09MlrBHuLe9ifIgYGkCFpYljJa0vfMkqhDgMYo8Qp3JkscvMGnLAbWBAAgYS8B0sqR+Ek8Mju+GuCTSHALaruior00pQl2sTM70HOwRzuk7nAIB2xDgP88NWFuiIQ9/+9vfKOK6ujqEPFjxbvNq7MWPuWDihD3CrXgnwGYQ8JaAkbJ0+vTpgss/QsisWbMKCgq+/vprQRBmzJgRGxu7evXqwsLC1NRUBIh726mGl5fPyPHXh/gR6kyWMFoyvGdhAAgEgICRsrR58+YrQxZIWlqaIAj0ddrWrVs7HI6BAwcePHjQIwi+Gx4vRwENCSjNyHH2+fY4WuJcq6HlqAoEQMAMBPjP8wBN4vkPgu+G//WjBvUE+BrjdsSjFKHOxklJ6TmIEVffBSgJApYmwH+eQ5Ys3bnGGM+fkVNaH5JHqDNNCnBMoDHU0CoIgMBPBCBLP5HA/zUi4MNoibYsiZK4MWtj5prinWU1DY0ujUxDNSAAAhYgAFmyQCdZy0SlGTk160PqY8qtxQTWggAIqCcAWVLPCiXVEpDPyPEj8dTWi3IgAAJBQACyFASdbISLkhk5rA8Z0QloEwQsSQCyZMlus4TRmJGzRDfBSBAwGwHIktl6BPaAAAiAQFATgCwFdfdr7jxGSJojRYUgEGwEIEvB1uM/+6u5hGA96We4SIEACPhKALLkKzmLX6e5hHi7D57F+cF8EAABvQhAlvQia+Z6NZcQH/bBMzMf2AYCIGAgAciSgfCNadpbCVEz1+fzzg7GIECrIAACJiYAWTJx5+hjmlcSonKuz7d98PTxD7WCAAhYmwBkyWL9p2bswndJvYSon+vzSur45uEsCIBAkBOALFnpBlA5duG7pFJCvJrr82cfPL61OAsCIBBsBCBLlulx9WMX5pLboZVKCVGpXqwtal5Seg77IAX2wWNwkAABEFBPALKknpWRJb0au1BDOUMrNRKSuaaYCYw84fazSZwWjWSHtkEABCxFALJkje7ybewilhPJ2IUvIQ2Nrl5ZG8WXS9JuPzIrCILb8Zk1EMNKEAABcxCALJmjHzxZoT5OgWpDSna+REic6TmSLx5xJISvgr2ycvFpPk89hvMgAAI+EoAs+QguwJfxdUIydvGqsFtH+CqYtabY7VXIBAEQAAH/CUCW/GcYiBpUxilQU/ii4nZZSOKD/8ImqRCHIAACIKCSAGRJJSjji6mJU6BW+i8qXqmg8WhgAQiAgI0IQJas1JmSOIXkqblz8g7Kl3k0ERX1KmglgrAVBEDA9AQgS6bvoisNbGh0zckrSZ6ayyIaemVtzFxTvLOsRqxPmoiKRAXx4fMruwJHIAACuhCALOmCVb9Kqd4wTRInJLKhiahwovX08xE1gwAIBDMByJKVel/ppVomTknpOeuLqphLEBWGAgkQAAGrEIAsWaWnfrSTH8sgfzPJSr7BVhAAARC4TACyZKUbgR/5zcZMkteYrOQhbAUBEAh6ApAlK90CHkdLVJnUvJlkJbdhKwiAQDARgCxZqbeVIr/ZOIkmMFqyUqfCVhAAgSsJQJau5GH6I3nkt1iTJLvemd4bGAgCIAACUgKQJSkRQ469CpmTRH4zWZLsEW6II2gUBEAABPwkAFnyE6AGl0tkRvL6kdsGqIxlrSnulfXze7XJmblz8krEL9W6vRaZIAACIGBmApAlg3tH/nqsV4Oey5s+HBRv+qBG1Qz2Gc2DAAiAgDIByJIyG/3PKL0eS5eItpdUryo4KtlVSGKUn6omqQ2HIAACIGA4AciSkV2gMuBbaQDEVzXM5hnZtWgbBEDAVwKQJV/JaXGdytdjlab1+KqGMHEtugh1gAAIBJoAZCnQxMXt8XWFhdgp7SrEVzW8VCtGjTQIgIBVCECWjOkpGkq34ovKXlkbk9JzxArESUsGQHxVkxQ2xk+0CgIgAAJeEoAseQlMi+KSiHCODklOSQZASps+0IiJ+kuNO8tqPAZNaOEQ6gABEAABzQhAljRDySrivxsrj52TaA/n8O1t5ZJABvmmD3QhKnvtvpTsfFaVUtAEsxkJEAABEDAJAciSxh0hGQlJ9EApds6ZntMrK/fD3ZXzt5Zfn7GByYk8IalQEAR5i9lr90kmBpWCJjR2HtWBAAiAgN8EIEt+IxRVIB8JSfSAvxrUK2ujXIckOZIKaePi8Vn9pUbxOIldju3yRB2FJAiAgHkJmFGWMjIyiOjXtWtXj/z4bni8XJMCnJFQn+l5dPKNHzvHJISf4AsMX/kQB6FJX6MSEAAB/Qjwn+dEv4Y5NWdkZFx33XXHf/pVV1dzCtNTfDc8Xq5JAb4ezMkrUfN5Wb4gic8qCQxf+SRBE5o4jkpAAARAQEMC/Oe5YbKUnJzslZN8N7yqyufCfD1wpuesL6pSip0T643KtJLA8NVRScx89hoXggAIgIC2BPjPc8NkKSoqqm3btp06dXrggQe+/vprtz5fuHCh7qdfZWUlIaSurs5tycBk8vXAmZ6Tkp3f0OiSx86p1CFJMSWBUVI+/tRfYBChFRAAARDwSMCMsrRu3br//Oc/e/fu3bBhQ9++fRMTE7///nu5J5IlKMNlibO2xBRle+mPE5KS2DnxxylYSU7Co8DIlc9toIQcKXJAAARAwHACZpQlMZRTp05dddVVb7/9tjiTps02WqJ6w5ETZ3pO8tTc9UVVgiCIY+fO1Te4Vaak9JzkzJ8/pySumVYiZ8JyJMonDytnJZEAARAAAVMRMLssCYJw0003TZo0iU+N7wb/Wm3Pzsk7KNYPeTrp8iIT1SfqjwAAE/NJREFUa1SiH6w8Hd9kr93HcsQJj7IkUT7JS7isdSRAAARAwGwE+M9zY9aWxIxOnz4dFxf36quvijPlab4b8vL65fywetRn+s/bK4i1hKbFU3Dy95xY+ZTs/LV7j7l9A4ktU+nnBWoGARAAAaMI8J/nxsjS008/vWXLloqKih07dtxxxx0tW7Y8efIkHxDfDf61mp/liA1THfpxPyXVuTFrI93RjpWXJ5RCHjR3BxWCAAiAQCAJ8J/nxsjSfffd17Zt2/Dw8Pbt2993331lZWUeifDd8Hi55gXWF1WJP2QuFxW6g6o8n+XsLKtZ8eVRdihPrPjyqOZmo0IQAAEQMJwA/3lujCz5AIXvhg8V+n/J9pJquZawHLq3NzuUJ1YVHH17W7k8n+W8va3cfyNRAwiAAAiYjQD/eQ5Z8r2/PL4/xH/P6cfR0heVTITkiRVfVPpuHK4EARAAAbMSgCzp2DP894f81y0dTUfVIAACIGAQAciSvuAl8d+S94fU6JZ8nIRIPH37DLWDAAgYSgCypDt+8Zuz8veH1OiWRJkkbz7p7gAaAAEQAIEAEoAsBRC2QlP+6JZClcgGARAAAasSgCxZoOf4umUBB2AiCIAACKgmAFlSjUqfgpAcfbiiVhAAAasSgCwZ2XP8hSUjLUPbIAACIGAQAciSQeAvf94iKT1HHM6Az08Y1hloGARAwDQEIEvGdIXSx5nEG7kaYxlaBQEQAAFDCUCWjMHvcYsHY8xCqyAAAiBgNAHIkjE9sKqAtw3rqgJsw2pMv6BVEAABwwlAlozpAoyWjOGOVkEABExPALLE6yL9orc9bojHMwvnQAAEQMC+BCBLin2rd/Q2f0M8RbNwAgRAAARsTQCy5L575V+YFUdvazWK0lv53PuGXBAAARAwMQHIkpvO4Udvr91bJf7YuWRTcDfVcbO0UjhuIzgJAiAAApYhAFly01X8eATxC7DO9BzxKMpNXcgCARAAARDwhgBk6UdakiELP3pbIktUmVKy8+UfrfCmI1AWBEAABEDgRwKQJUG+wDPu/S/k2uMxZ2dZDe4pEAABEAABPwkEuyy5DW3wqEBuC+AdWD/vRVwOAiAAAsE+WlIKbXCrOh4zMVrC3ygQAAEQ8J9AUI+WvAptoLKUPDVXsu031pb8vwtRAwiAAAgwAkEtS96GNjjTc8a9/wUNvWODJ0TisZsJCRAAARDwn0BQy5IPo6WU7Py1e49p+N6S/12IGkAABEDATgSCWpaUNqZjIyG3iZ1lNZKAcjvdEPAFBEAABIwlENSyJPz0iVjxcpE47VaWEHFn7C2L1kEABOxNINhliSqTZFJuTl6JW0GimYi4s/dfCXgHAiBgLAHI0o/8JZNySpN7+KK5sTcrWgcBEAgGApAl972Mr06454JcEAABENCZAGRJEbB8U6L1RVWKpXECBEAABEBACwKQJR5FyeQeryjOgQAIgAAIaEEAsqQFRdQBAiAAAiCgEQHIkkYgUQ0IgAAIgIAWBCBLWlBEHSAAAiAAAhoRgCxpBBLVgAAIgAAIaEEAsqQFRdQBAiAAAiCgEQHIkkYgUQ0IgAAIgIAWBCBLWlBEHSAAAiAAAhoRgCxpBBLVgAAIgAAIaEEAsqQFRdQBAiAAAiCgEQHIkkYgUQ0IgAAIgIAWBGwiS7W1tYSQysrKOvxAAARAAASsTKCyspIQUltb61bjiNtcE2ZSNwh+IAACIAACtiBQWVnpVmssI0uNjY2VlZW1tbU+/BOBShpGWmJ0YCKmQdNgImECIBIgdXV1YKIJk9ra2srKysbGRmvLklvrVWby5zFVVmKzYmAi71AwkTABEAkQQRDAJABMLDNakrNQn4M7Sc4KTMBETkCSg5tEAgSyJAeiBxPIklvO9s/EE0fex2AiYQIgEiB6PILlTVguR/P7JChk6cKFCxkZGT/8abn+1s9gMJGzBRMJEwCRABEEAUwCwCQoZEnOETkgAAIgAALmJABZMme/wCoQAAEQCFICkKUg7Xi4DQIgAALmJABZMme/wCoQAAEQCFICkKUg7Xi4DQIgAALmJBAUsjR37lyn0+lwOHr37v3pp5+asycCZlV2dvZNN90UHR2dkJCQmpp64MCBgDVt/oZefvllQsiECRPMb6reFh49evTBBx+Mj4+PiIjo0aPH559/rneLJq+/oaHhr3/9a1JSUkRExNVXX52VleVyuUxus+bmbd26dfjw4W3btiWErFy5ktXvcrlefPHFNm3aREREDBw4sKSkhJ3yIWF/Wfrggw/Cw8MXLVq0b9++0aNHx8bGfvPNNz6Qss0lgwcPXrx4cXFx8Z49e4YOHZqYmHjmzBnbeOePI5999llSUtL1118PWfruu++cTucjjzzy6aefHjp0KDc3t6yszB+2Nrh2+vTpLVq0yMnJqaioWLZsWXR09KuvvmoDv7xyYd26dS+88MKKFSsksjRjxoyYmJhVq1bt3bt3xIgRnTp1On/+vFc1iwvbX5Z69+49btw46nNjY2O7du1efvllMYJgTp88eZIQsnXr1mCGQH0/ffp0ly5d8vLyBgwYAFlKT0//1a9+hbtCTGDYsGGPPfYYy7nrrrsefPBBdhhsCbEsuVyuNm3azJw5k0Kora11OBxLly71mYnNZam+vj40NFQ82Bw1atSIESN85mWzC0tLSwkhRUVFNvPLB3dGjRo1ceJEQRAgS4IgdOvWbeLEiXfffXdCQsINN9wwf/58H5Da7JLp06c7nc6DBw8KgrBnz55WrVq99957NvNRvTtiWSovLyeEFBQUsMv79+//5z//mR16m7C5LB07dowQsnPnTsbl2Wef7d27NzsM5kRjY+OwYcP69esXzBCo70uXLu3RoweddoAsCYLguPx7/vnnv/zyy7feeisiIuKdd94J8vuksbExPT09JCSkadOmISEh2dnZwQxELEs7duwghFRVVTEg99xzz7333ssOvU1AlrwlZp/yY8aMcTqdSp88sY+fnjw5cuRIq1at9u7dSwtClgRBCAsL69u3LyM3fvz4lJQUdhiciaVLl3bo0GHp0qWFhYVLliyJj48PZqmGLPn+twCTeErsxo0b16FDh0OHDikVCJ78lStXEkJCf/oRQkJCQkJDQxsaGoIHgsTTxMTExx9/nGXOmzevXbt27DA4Ex06dJg7dy7zfdq0aV27dmWHwZYQyxIm8bzu/d69e//pT3+ilzU2NrZv3z7IQx5cLte4cePatWvnZxCn1z1h1gu+//77ItHvpptueuihh4J8ve3+++8XhzxMnDhRPHgya0/qa1d8fPy8efNYG9nZ2V26dGGHwZYQyxINefjb3/5GIdTV1SHkwcP98MEHHzgcjnfeeWf//v1//OMfY2NjT5w44eEaW58eO3ZsTEzMli1bjv/0O3funK099s45TOIJgvDZZ581bdp0+vTppaWl77//flRUVDAv79MbKC0trX379jRAfMWKFS1btnzuuee8u7esX/r06dMFl3+EkFmzZhUUFHz99deCIMyYMSM2Nnb16tWFhYWpqakIEPfc1f/4xz8SExPDw8N79+793//+1/MFti5BZL/Fixfb2mPvnIMsUV4fffRRjx49HA7Htddei0g8QRC+//77CRMmJCYm0tdpX3jhhfr6eu/uLeuX3rx5s+T5kZaWJggCfZ22devWDodj4MCBNF7RZ3dtHvLgMxdcCAIgAAIgYAgByJIh2NEoCIAACICAewKQJfdckAsCIAACIGAIAciSIdjRKAiAAAiAgHsCkCX3XJALAiAAAiBgCAHIkiHY0SgIgAAIgIB7ApAl91yQCwIgAAIgYAgByJIh2NEoCIAACICAewKQJfdckAsCmhBYuXJl586dmzRpYp5vODmdztmzZ2viHSoBAT0IQJb0oIo6A03A5XINHDhw0KBB4oZff/31mJgYY7dIb9WqVXp6+rFjx77//nuxbYIgOJ1OyQvzgdmt8eTJk2fPnpUYg0MQMA8ByJJ5+gKW+EXgyJEjMTExb775Jq3l0KFDzZo1W7JkiT+VXrx40Z/LT58+TQj5+OOP3VbidDqzsrJ+2pjwx//r/fX6INwsxy15ZJqcAGTJ5B0E87wg8M4770RHRx86dMjlct12220jR44sKioaMmRIs2bNWrVq9dBDD1VXV9Pq1q9f369fv5iYmPj4+GHDhpWVldH8iooKQsgHH3zQv39/h8OxePHiw4cPDx8+PDY2Nioqqnv37mvXrpUb9N133z388MOxsbGRkZFDhgyhW7NLdg/bvHmz5EKlybTMzMy2bdvW1NTQ8kOHDr311lsbGxsFQSCEzJs3b8iQIREREZ06dVq2bBmr88iRI/fcc09MTExcXNyIESMqKiroqbS0tNTU1Jdeeqlt27ZJSUl0lMYm8U6dOvX444+3bNmyefPmt9122549e+hVGRkZycnJS5YscTqdV1111X333cdGe42Nja+88krnzp3Dw8M7duz40ksv0UuUDGAWIgECKglAllSCQjFrEEhNTb311ltfe+21hISEkydPJiQkPP/881999dWXX375m9/85rbbbqNuLF++/MMPPywtLS0oKPjtb3/bs2dP+tynspSUlPThhx8eOnSoqqpq2LBhv/nNbwoLC8vLyz/66KOtW7fKQYwYMaJbt27btm3bs2fP4MGDr7nmmosXL9bX1x88eJAQ8uGHHx4/flw+UlGSpYaGhr59+/7ud78TBGHu3LmxsbF0k2YqSy1atFiwYMHBgwf/+te/hoaG7t+/XxCEixcvduvW7bHHHissLNy/f/8DDzzQtWtX2mJaWlp0dPTDDz9cfPknkaU77rjjt7/97eeff15SUvL000+3aNHi22+//cHBjIyM6Ojou+66q6ioaNu2bW3atJk8eTJ1/LnnnouLi3vnnXfKyso++eSTBQsW8A2Q40IOCPAJQJb4fHDWYgS++eabli1bNmnSZOXKldOmTROvNlVWVhJC5HsbV1dXE0LoB5aoLM2ZM4e53bNnz6lTp7JDeaKkpIQQsmPHDnqqpqYmMjLyP//5jyAIp06dIoTIx0m0pNPpDA8Pbyb6bdu2jZ4qLy9v3rx5enp6ZGTk+++/zxolhIwZM4Yd9unTZ+zYsYIgvPvuu127dnW5XPRUfX19ZGRkbm6uIAhpaWmtW7cWiyKTw08++eSqq666cOECq7Bz585vvfXWD4cZGRlRUVFshPTss8/26dOH7qLtcDioFLGr+AaIiyENAmoIQJbUUEIZKxF44YUXrrvuOkEQ7r777rCwMNFjvxkhZN26dYIglJSU/OEPf+jUqVPz5s2bNfsxn87OUVnavn07c3jBggVNmza95ZZbpkyZwj6szs4KgrB69eqmTZuKP2V7ww03ZGZmqpGlF154oVT0E3/46q233iKE3HfffeK2CCH//Oc/Wc7EiRNvvfVWQRCeeeaZ0NBQsachISH0m3VpaWl33HEHu0Q8Wpo7d26TJk3EVzVp0oR+QygjI6N79+7sqlmzZnXq1EkQhE8//ZQQIv+oMccAVgkSIKCSAGRJJSgUswwBui4iCMKQIUPuuusu0WP/xyQNK+jateugQYPy8/P3799fXFzMPrVJZamgoEDs7ZEjR954442RI0eGhYW99tpr4lN+yhJb45HUKQjCgw8+GBoa2qdPn0uXLrGzSrI0ZsyY3r17Szytra2lo6XU1FRWg1iWZsyY0b59e8lVdPmNMaQXzp492+l0CoJQWFjoVpY4BoibRhoE1BCALKmhhDJWIsAeqZMnT+7atav4sU7dqKmpIYSwGbNPPvmEL0vM+UmTJvXs2ZMd0oTbSTwajOBxEk9Jlj744IPIyMhPPvmkbdu2U6ZMYS0SQuisHc1JSUmhh/Pnz4+Li6urq2MlWYKGPLBDsSxt3LgxNDSUBUeIyzCGNJPJ0vnz5yMjI+WTeBwDxNUiDQJqCECW1FBCGSsRYI/UY8eOJSQk3H333Z999llZWdmGDRseeeSRhoaGxsbGFi1aPPTQQ6WlpZs2bbr55ps5sjRhwoQNGzYcOnToiy++6NOnz7333itnkZqa2r17908++WTPnj1DhgyhIQ9qJvEkAeJUVyorK+Pi4uiwbMOGDU2bNt21axdtlBDSsmXLhQsXHjx4cMqUKU2aNNm3b58gCGfPnu3Spcutt966bdu2Q4cObd68efz48fSFLY4suVyuX/3qV8nJybm5uRUVFTt27Jg8efLnn3/+Q1uMIW2XydIPYRdTp06Ni4v75z//WVZWtmvXrrfffptvgBwXckCATwCyxOeDs9YjIH6klpSUjBw5koZuX3vttRMnTqRxAXl5ed26dXM4HNdff/2WLVs4svSnP/2pc+fODocjISHh4YcfZnHbYi40QDwmJiYyMnLw4ME0QFyNLElep33iiSfoe8GDBw9m8Qvjx4/v3Lnz6dOnaSTe66+//pvf/MbhcCQlJf373/9mZhw/fnzUqFEtW7Z0OBxXX3316NGjqchxZImGMIwfP75du3ZhYWEdO3Z88MEHjxw58kOdYoaCIIhlqbGx8aWXXnI6nWFhYYmJidnZ2dQGJQOYhUiAgEoCkCWVoFAMBIwnwOTTeFNgAQjoRgCypBtaVAwCWhOALGlNFPWZkQBkyYy9AptAwC0ByJJbLMi0GQHIks06FO6AAAiAgLUJQJas3X+wHgRAAARsRgCyZLMOhTsgAAIgYG0CkCVr9x+sBwEQAAGbEYAs2axD4Q4IgAAIWJsAZMna/QfrQQAEQMBmBCBLNutQuAMCIAAC1iYAWbJ2/8F6EAABELAZAciSzToU7oAACICAtQlAlqzdf7AeBEAABGxG4P8DOJghxXJNcdMAAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "Sl0Hl1SUT4Eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the sample data"
      ],
      "metadata": {
        "id": "lALh8VvjT5qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a sample dataset\n",
        "np.random.seed(0)\n",
        "X_uni = np.random.rand(100, 1) * 10  # Years of experience (between 0 and 10)\n",
        "y_uni = 3 * X_uni + 2 + np.random.randn(100, 1)  # Salary, with some noise"
      ],
      "metadata": {
        "id": "4mpRs-E7B3m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the data\n",
        "# YOUR CODE HERE use a scatter plot ro visualize the data"
      ],
      "metadata": {
        "id": "dM2-_zGF6TGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X_uni_tensor = torch.tensor(X_uni, dtype=torch.float32)\n",
        "y_uni_tensor = torch.tensor(y_uni, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "r9KRWnJ2gquj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Linear Regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "mOjWUY48gtME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "t9Sb4i7egw02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and the optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "JjhywLLngvd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    outputs = model(X_uni_tensor)  # Forward pass\n",
        "    loss = criterion(outputs, y_uni_tensor)  # Compute the loss\n",
        "    loss.backward()  # Backward pass\n",
        "    optimizer.step()  # Update the weights\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "Rt3CWUiZg0R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_tensor = model(X_uni_tensor)"
      ],
      "metadata": {
        "id": "Kl1XWm-Zg38p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions to numpy array\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "1Y5F9gKZg5vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the model coefficients\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "u2OY-j0wg7P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the results\n",
        "plt.scatter(X_uni, y_uni, color='blue', label='Original data')\n",
        "plt.plot(X_uni, y_pred, color='red', label='Fitted line')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CaW0BsBschae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A basic neural network architecture consists of an input layer, one or more hidden layers, and an output layer. The input layer receives the raw data, with each neuron representing a feature. Hidden layers contain neurons that process inputs using learned weights and biases, applying an activation function (like ReLU or sigmoid) to introduce non-linearity. The output layer produces the final prediction, with neurons corresponding to the output classes (for classification) or a single neuron (for regression). The network learns by adjusting weights and biases to minimize a loss function using backpropagation and an optimization algorithm like gradient descent."
      ],
      "metadata": {
        "id": "8112-N4DhXB5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbm-8HxIqvxR"
      },
      "source": [
        "## Initializing CUDA\n",
        "\n",
        "CUDA is used as an interface between the code and the GPU.\n",
        "\n",
        "Normally, the code is run in the CPU. To run it in the GPU, we need CUDA. Check if CUDA is available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHj_ZREiqvxU"
      },
      "outputs": [],
      "source": [
        "# To test whether GPU instance is present in the system or not.\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Using PyTorch version:', torch.__version__, 'CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuGyWSz8q4NQ"
      },
      "source": [
        "If it's False, then the program is executed on CPU. If it's True, then the program is executed on GPU.\n",
        "\n",
        "Initialize some GPU-related variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_WeWksDqvxb"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Multivariate Classification"
      ],
      "metadata": {
        "id": "vejQc2Q-Bhd7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijqHaydutZ5K"
      },
      "source": [
        "### Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MNIST digits dataset is a widely used benchmark in machine learning and computer vision. It consists of 70,000 grayscale images of handwritten digits, ranging from 0 to 9. Each image is 28x28 pixels, resulting in a total of 784 features per image. The dataset is split into 60,000 training images and 10,000 test images. Each image is labeled with the correct digit, making it a supervised learning dataset. MNIST is commonly used for training and testing image classification algorithms, particularly in the fields of neural networks and deep learning."
      ],
      "metadata": {
        "id": "VLAcXy5RrF1_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkBWGgw7cUFP"
      },
      "source": [
        "## Load MNIST data\n",
        "\n",
        "Load the MNIST data. It can take a while.\n",
        "\n",
        "\n",
        "* Load both the training set and the testing sets\n",
        "\n",
        "* Use  transform.compose() to convert the datasets into tensors using transforms.ToTensor(). We also normalize them by setting the mean and standard deviation using transforms.Normalize()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hillq61ILyG5"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with an image, text, audio, or video footage, one would use Python packages to load that data into a NumPy array and then convert the array into a tensor. Fortunately, PyTorch makes the process easier by offering a library called torchvision. This library provides useful tools such as data loaders, datasets, and data transformers for pixelated images."
      ],
      "metadata": {
        "id": "v2OyUAtcw0Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Image Preprocessing with transforms.Compose**\n",
        "\n",
        "When working with image data in deep learning, especially in PyTorch, preprocessing steps are essential to ensure the data is in the right format and range for the neural network.\n",
        "\n",
        "Two common preprocessing steps are converting images to tensors and normalizing their pixel values. This section explains why these steps are necessary and how they are achieved using torchvision.transforms.\n",
        "\n",
        "Why Preprocess Images?\n",
        "\n",
        "1. Conversion to Tensors:\n",
        "\n",
        "  * Neural networks in PyTorch require input data to be in the form of tensors. Tensors are the primary data structure in PyTorch, similar to arrays in NumPy but with added functionality for GPU acceleration.\n",
        "\n",
        "  * Converting images to tensors ensures compatibility with PyTorch's neural network modules and allows efficient computation.\n",
        "\n",
        "\n",
        "2. Normalization:\n",
        "\n",
        "  * Normalizing images is a crucial step that helps in faster convergence during training. It scales the pixel values to a standardized range, which can lead to more stable and faster training.\n",
        "\n",
        "  * Typically, pixel values of images range from 0 to 255. However, for neural networks, it's beneficial to have these values in a smaller range, often between -1 and 1.\n",
        "\n",
        "  * Normalizing the data helps to ensure that each input feature (in this case, pixel values) has a similar distribution, which helps the neural network learn more effectively."
      ],
      "metadata": {
        "id": "NMu361lmJCyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])"
      ],
      "metadata": {
        "id": "LHmCYjbFwRvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's break down each transformation:**\n",
        "\n",
        "1. transforms.ToTensor():\n",
        "\n",
        "  * Converts a PIL Image or NumPy ndarray to a PyTorch tensor.\n",
        "\n",
        "  * Scales the pixel values from the range [0, 255] to [0.0, 1.0].\n",
        "\n",
        "2. transforms.Normalize((0.5,), (0.5,)):\n",
        "\n",
        "  * Normalizes the tensor image with a mean of 0.5 and a standard deviation of 0.5.\n",
        "  * The formula used for normalization is:\n",
        "  \n",
        "$$ \\text{normalized_pixel} = \\frac{\\text{original_pixel} - \\text{mean}}{\\text{std}} $$\n",
        "  ​\n",
        "\n",
        "  * Given the original pixel values are in [0.0, 1.0], normalizing with mean=0.5 and std=0.5 will transform these values to the range [-1.0, 1.0]."
      ],
      "metadata": {
        "id": "kNmquEezxETw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=20, shuffle=True)\n",
        "\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=20, shuffle=True)"
      ],
      "metadata": {
        "id": "w9Cog-rJw214"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, there is a training set, testing set, train loader, and test loader.\n",
        "\n",
        "When working with large amounts of data, the DataLoader class is useful because it generates the data on multiple cores in real-time and directly feeds it into the deep learning model.\n",
        "\n",
        "A DataLoader can be given a batch_size, which denotes the number of samples in each generated batch, and the shuffle parameter can be set to randomize the data sequence."
      ],
      "metadata": {
        "id": "LX7jbYK3xUxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    # YOUR CODE HERE check the size and type of training set"
      ],
      "metadata": {
        "id": "2SguqdsHxHTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUTWWsGtnC2h"
      },
      "source": [
        "The train and test data are provided via data loaders that provide iterators over the datasets.\n",
        "\n",
        "The first element of training data (X_train) is a 4th-order tensor of size (batch_size, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels. y_train is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training image. Here batch size is 20.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXXtfQXgmEO7"
      },
      "source": [
        "## Plotting the images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels =[]\n",
        "features = []\n",
        "for X,y in zip(X_train, y_train):\n",
        "  # Getting unique labels\n",
        "  if y not in labels:\n",
        "    labels.append(y)\n",
        "    features.append(X)\n",
        "\n",
        "pltsize=1\n",
        "plt.figure(figsize=(7,7))\n",
        "for i in range(5):\n",
        "    plt.subplot(3,3, i+1)\n",
        "    plt.axis('off')\n",
        "    # Convert the tensor to numpy for displaying the image\n",
        "    plt.imshow(features[i].numpy().reshape(28,28), cmap=\"gray\")\n",
        "    plt.title(f'Label: {labels[i]}')"
      ],
      "metadata": {
        "id": "yNbOwsMMxrSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_ey0gh9UNmJ"
      },
      "source": [
        "### Dense Neural Network Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwx1h5H2UNmJ"
      },
      "source": [
        "Dense Neural Networks can be used for classification and regression tasks. In classification, they can perform (i) Binary Classification (ii) Multilabel Binary Classification, and (iii) Multiclass classification\n",
        "\n",
        "* **Binary classification:** Used when there are only two distinct classes and the data we want to classify belongs exclusively to one of those classes, e.g. classifying if a review sentiment is positive or negative.\n",
        "\n",
        "* **Multilabel binary classification:** Used when there are two or more classes and the data we want to classify belongs to none of the classes or all of them at the same time, e.g. classifying which traffic signs are shown in an image.\n",
        "\n",
        "  Note that the output probabilities do not necessarily add up to 1. This lets the model output any combination of labels\n",
        "\n",
        "* **Multiclass classification:** Used when there are three or more classes and the data we want to classify belongs exclusively to one of those classes, e.g.  out of three or more possible classes (e.g., classes 0 through 9 for digit image classification), we need to have one output neuron per class, and we should use the **softmax activation function** for the whole output layer as shown in the figure below. The softmax function will ensure that all the estimated probabilities are between $0$ and $1$ and that they add up to $1$.\n",
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://www.oreilly.com/api/v2/epubs/9781492037354/files/assets/mlst_1009.png\" width=500px/>\n",
        "</center>\n",
        "\n",
        "Regarding the loss function, since we are predicting probability distributions, the cross-entropy loss (also called the log loss) is generally a good choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEYZoawOppFN"
      },
      "source": [
        "## Defining the Dense Neural Network’s Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ExHDyD98WtB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The given code defines a neural network architecture in PyTorch, consisting of a series of fully connected (dense) layers. This architecture is designed for image classification, particularly suitable for datasets like MNIST, where each image is 28x28 pixels.\n",
        "\n",
        "Architecture Details:\n",
        "1. **Input Layer**: The model accepts input images flattened into a 1D array of size 784 (28x28).\n",
        "2. **First Fully Connected Layer (fc1)**: This layer maps the 784 input features to 256 neurons. The activation function used is ReLU (Rectified Linear Unit), which introduces non-linearity.\n",
        "3. **Second Fully Connected Layer (fc2)**: This layer further reduces the feature dimensions from 256 to 128, with ReLU activation.\n",
        "4. **Third Fully Connected Layer (fc3)**: The feature dimensions are reduced from 128 to 64, again with ReLU activation.\n",
        "5. **Output Layer (fc4)**: The final layer outputs 10 neurons, corresponding to the 10 possible classes (digits 0-9). The output is passed through a log-softmax function, which converts the raw output scores into log probabilities.\n",
        "\n",
        "Model Forward Pass:\n",
        "In the `forward` method, the input tensor `x` is first reshaped to ensure it has the correct dimensions for processing. It is then passed through each fully connected layer with ReLU activations applied at each step, except the output layer. The final output, `x`, represents the log probabilities of each class."
      ],
      "metadata": {
        "id": "7QTVXpVucx2s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlTLMs5Q-6Uh"
      },
      "source": [
        "#### Calling the instances of the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5DecLBbmnYC"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE create the model instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3RpbpWiJkJr"
      },
      "outputs": [],
      "source": [
        "summary(model, input_size=(1,28,28), batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgJQ6bNG-Mx0"
      },
      "source": [
        "#### Defining the loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjUUgDMQmw7Y"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmNz24u_n5fw"
      },
      "source": [
        "#### Training and Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "<center>\n",
        "<img src=\"https://cdn.exec.talentsprint.com/static/aimlops/c3/Train.png\" width=500px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "_HZ_f-RLBSY6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWcqXz9PAM9B"
      },
      "source": [
        "In Training Phase, iterate over a batch of images in the train_loader. For each batch, perform  the following steps:\n",
        "\n",
        "* First zero out the gradients using zero_grad()\n",
        "\n",
        "* Pass the data to the model i.e. perform forward pass by calling the forward()\n",
        "\n",
        "* Calculate the loss using the actual and predicted labels\n",
        "\n",
        "* Perform Backward pass using backward() to update the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG_e4hjdrgs7"
      },
      "outputs": [],
      "source": [
        "# No of Epochs\n",
        "epoch = 2\n",
        "\n",
        "# keeping the network in train mode\n",
        "model.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Accuracy calculation\n",
        "    train_losses.append(train_loss/len(mnist_trainset))\n",
        "    train_accuracy.append(100 * correct/len(mnist_trainset))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f} '.format(e+1,train_losses[-1], train_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdg2JUD1BxOC"
      },
      "source": [
        "In Testing Phase, iterate over a batch of images in the test_loader. For each batch, perform the following steps:\n",
        "\n",
        "* Pass the images through the model (network) to get the outputs\n",
        "* Pick the class / label with the highest probability\n",
        "* Calculate the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEZPsRndr1i9"
      },
      "outputs": [],
      "source": [
        "# Keeping the network in evaluation mode\n",
        "# YOUR CODE HERE set the model to evaluation mode\n",
        "\n",
        "# Iterate through all the batches in each epoch\n",
        "for images,labels in test_loader:\n",
        "\n",
        "    # Convert the images and labels to gpu for faster execution\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    outputs = model(images)\n",
        "\n",
        "    # Accuracy calculation\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    Test_accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "# YOUR CODE HERE print the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKm6IXufWM8U"
      },
      "source": [
        "## Transfer Learning with Pretrained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXZqSaeVXKiV"
      },
      "source": [
        "#### Introduction to Transfer Learning\n",
        "\n",
        "Transfer learning is a machine learning technique where a model developed for one task is reused as the starting point for a model on a second task. This is especially useful in deep learning where training models from scratch can be computationally expensive and require large amounts of data. Instead of training a model from the ground up, transfer learning leverages the knowledge acquired by a pre-trained model on a large dataset, transferring this knowledge to a new, related task.\n",
        "\n",
        "#### How Transfer Learning Works\n",
        "\n",
        "1. **Pre-training**: A model is first trained on a large and diverse dataset. For instance, models like VGG, ResNet, and BERT are pre-trained on datasets such as ImageNet for image tasks and large corpora of text for NLP tasks.\n",
        "2. **Fine-tuning**: The pre-trained model is then fine-tuned on the specific dataset of the target task. This involves either:\n",
        "   - Using the pre-trained model as a fixed feature extractor, where the pre-trained layers are frozen, and only the final layer(s) are trained.\n",
        "   - Unfreezing some of the pre-trained layers and training them along with the final layers to adapt the model more closely to the new task.\n",
        "\n",
        "#### Benefits of Using Pre-trained Models\n",
        "\n",
        "1. **Reduced Training Time**: Pre-trained models significantly cut down the time required to train a model. Since the pre-trained model has already learned a lot of features, the training process focuses on fine-tuning these features rather than learning from scratch.\n",
        "\n",
        "2. **Improved Performance**: Models pre-trained on large datasets typically capture a wide variety of features that can be beneficial for the target task. This usually results in better performance compared to models trained from scratch, especially when the target dataset is small.\n",
        "\n",
        "3. **Data Efficiency**: Transfer learning is particularly valuable when the target task has limited data. The pre-trained model can generalize better from limited data, leveraging the knowledge it gained from the large pre-training dataset.\n",
        "\n",
        "4. **Overfitting Prevention**: Pre-trained models, having been exposed to a large amount of diverse data, are less prone to overfitting on small datasets. This helps in creating more robust models.\n",
        "\n",
        "5. **Access to Advanced Architectures**: Utilizing pre-trained models often means leveraging advanced model architectures that have been extensively tested and validated by the research community. This provides a strong starting point for building state-of-the-art solutions.\n",
        "\n",
        "#### Examples in Practice\n",
        "\n",
        "1. **Image Classification**: Transfer learning is widely used in image classification tasks. Models pre-trained on the ImageNet dataset are commonly used as the basis for tasks involving medical imaging, object detection, and more.\n",
        "\n",
        "2. **Natural Language Processing (NLP)**: In NLP, models like BERT, GPT, and T5, pre-trained on massive text corpora, are fine-tuned for specific tasks such as sentiment analysis, named entity recognition, and question answering.\n",
        "\n",
        "3. **Speech Recognition**: Models pre-trained on large speech datasets are fine-tuned for specific applications like voice assistants, transcription services, and more.\n",
        "\n",
        "Transfer learning, particularly with pre-trained models, offers a powerful approach to machine learning by leveraging existing knowledge to tackle new problems efficiently and effectively. By reducing training time, improving performance, enhancing data efficiency, preventing overfitting, and providing access to advanced architectures, transfer learning enables practitioners to develop high-performing models even with limited resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMbIq3rZlrUO"
      },
      "source": [
        "### Visualizing one image from the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB7EQosBovSk"
      },
      "outputs": [],
      "source": [
        "# Iterate through the testloader and extract one image and label\n",
        "for images, labels in test_loader:\n",
        "  image = images[0]  # Take the first image from the batch\n",
        "  label = labels[0]  # Take the corresponding label\n",
        "  break  # Exit the loop after extracting one sample\n",
        "\n",
        "# Print the shape of the image and the label\n",
        "print(\"Image shape:\", image.shape)\n",
        "print(\"Label:\", label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL7FRzBwpEvr"
      },
      "outputs": [],
      "source": [
        "# Reshape the image to [1, 1, 28, 28]\n",
        "image_reshaped = image.unsqueeze(0)  # Add a batch dimension\n",
        "print(\"Reshaped image shape:\", image_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAv5etOeqeIs"
      },
      "outputs": [],
      "source": [
        "# Convert the tensor to numpy for displaying the image\n",
        "# YOUR CODE HERE  # Remove batch dimension and convert to numpy\n",
        "\n",
        "# Display the image\n",
        "# YOUR CODE HERE\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OXjvs-imOkR"
      },
      "source": [
        "### Load ResNet50 model and fine-tune it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uUyPEWKPiw7"
      },
      "outputs": [],
      "source": [
        "# Load pretrained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6-5eQswbPaQ"
      },
      "outputs": [],
      "source": [
        "# Modify the final fully connected layer to match the number of classes in Fashion MNIST\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Move the model to the device (GPU if available)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Y4ug5asKV-"
      },
      "source": [
        "Training is expected to take time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7C3kIKkcTtn"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "epoch = 2\n",
        "model.train()\n",
        "train_losses, train_accuracy = [], []\n",
        "\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        resize_transform = transforms.Resize((224, 224))\n",
        "        resized_image = resize_transform(images)\n",
        "        resized_image = resized_image.repeat(1, 3, 1, 1)\n",
        "        images = resized_image.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_losses.append(train_loss / len(mnist_trainset))\n",
        "    train_accuracy.append(100 * correct / len(mnist_trainset))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f} '.format(e + 1, train_losses[-1], train_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stTeFTEscF-u"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "Test_accuracy = 0\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    resize_transform = transforms.Resize((224, 224))\n",
        "    resized_image = resize_transform(images)\n",
        "    resized_image = resized_image.repeat(1, 3, 1, 1)\n",
        "    images = resized_image.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    Test_accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "Accuracy = 100 * Test_accuracy / len(mnist_testset)\n",
        "print(\"Accuracy of Test Data is\", Accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "outputs": [],
      "source": [
        "#@title What is the role of feature engineering in predictive modeling? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"To clean the data\", \"To create new features from existing data\", \"To split the data into training and test sets\", \"To evaluate the model\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ]
}
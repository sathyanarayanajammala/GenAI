{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathyanarayanajammala/GenAI/blob/main/Langchain_Chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQeblWrXV2IQ"
      },
      "source": [
        "# Generative AI and Prompt Engineering\n",
        "## A Program by IISc and TalentSprint\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LangChain: Chains**"
      ],
      "metadata": {
        "id": "hfKf6HJrdEov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1oWVGD1PLFPc"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "BJMXW3uhL7lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/openapi_key.txt')\n",
        "api_key = f.read().strip()          # Remove Blank Spaces\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "openai.api_key= os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "LPMBGQ3EL-bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "NY7lVlZALhNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Most Basic chain**\n",
        "[LCEL:Getting Started](https://python.langchain.com/v0.1/docs/expression_language/get_started/)\n",
        "\n",
        "**Example:1**\n",
        "\n",
        "Notice: `.from_template`"
      ],
      "metadata": {
        "id": "B6DyFd4sR23I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = \"gpt-3.5-turbo\" # This is a chat model\n",
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
      ],
      "metadata": {
        "id": "3oD-7RtYSur5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name to describe \\\n",
        "    a company that makes {product}?\"\n",
        ")"
      ],
      "metadata": {
        "id": "wySpxRJRR2Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1"
      ],
      "metadata": {
        "id": "LmO2SxHtcS6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = prompt1 | llm |StrOutputParser() # Try with or without-> |StrOutputParser()"
      ],
      "metadata": {
        "id": "nSqldbz7SrWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LCEL(LangChain Expression Language)**--> uses pipes(|):  When we call invoke() on the chain, the input is first passed to prompt, output of that is passed to the llm. It's just the combination of the LLM\n",
        "and the prompt. But now this chain will let us run through the\n",
        "prompt and into the LLM in a sequential manner."
      ],
      "metadata": {
        "id": "YKEPwQI3TdTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product = \"mobile\"\n",
        "result= chain1.invoke(product)\n",
        "result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jyTqvM0sTIk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example:2**\n",
        "\n",
        "Notice: `.from_messages`"
      ],
      "metadata": {
        "id": "fdxJz8hPT_LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2=ChatPromptTemplate.from_messages([(\"system\",\"You are a knowladgeable historian\" ),\n",
        "                                          (\"human\",\"say 3 lines about {input}\")])\n",
        "prompt2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Rh8i61YuT6Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = prompt2| llm |StrOutputParser() # LCEL --> LangChain Expression Language"
      ],
      "metadata": {
        "id": "qzhvQNSAT9YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event = \"India Gate\"\n",
        "result= chain2.invoke({'input':event})\n",
        "result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TieyFYtFULsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Runnable**\n",
        "\n",
        "A Runnable is a unit of execution in the LangChain framework. It represents a specific task or operation that can be performed.\n",
        "Examples of Runnables include data transformations, computations, or any other operation that can be expressed in the LangChain expression language."
      ],
      "metadata": {
        "id": "MK62TOaoV7x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: [Runnable Lambdas](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableLambda.html)**\n",
        "\n",
        "The RunnableLambda is a LangChain abstraction that allows us to turn Python functions into pipe-compatible functions, similar to the Runnable class."
      ],
      "metadata": {
        "id": "PVErfQ48WIBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda"
      ],
      "metadata": {
        "id": "KRmGKzQK4lmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_five(x):\n",
        "    return x + 5\n",
        "\n",
        "def multiply_by_two(x):\n",
        "    return x * 2\n",
        "\n",
        "# wrap the functions with RunnableLambda\n",
        "chain = RunnableLambda(add_five) | RunnableLambda(multiply_by_two)\n"
      ],
      "metadata": {
        "id": "Ll02Oang4u1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(3)"
      ],
      "metadata": {
        "id": "2h6SU5FReYIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A RunnableSequence constructed using the `|` operator\n",
        "sequence = RunnableLambda(lambda x: x + 1) | RunnableLambda(lambda x: x * 2)\n",
        "sequence.invoke(1)"
      ],
      "metadata": {
        "id": "s_ned6Cv4N95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2 : [RunnablePassthrough](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)** on its own allows you to pass inputs unchanged. This typically is **used in conjuction with [RunnableParallel](https://python.langchain.com/v0.1/docs/expression_language/interface/#parallelism)** to pass data through to a new key in the map."
      ],
      "metadata": {
        "id": "93DIOu3OWgcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified = lambda x:   x[\"num\"] + 1  ,\n",
        ")"
      ],
      "metadata": {
        "id": "uvf0VTezWlAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable.invoke({\"num\": 3})"
      ],
      "metadata": {
        "id": "ljpreY2efkLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3: RunnableMap**: Parallel Execution -\n",
        "The RunnableMap class runs a mapping of Runnables in parallel. It takes a list of inputs and applies each Runnable to its corresponding input.\n",
        "The result is a mapping of the outputs from each Runnable.\n",
        "Essentially, it allows you to process multiple inputs concurrently and collect their outputs in a structured way."
      ],
      "metadata": {
        "id": "XcDo2VLMXi1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Fictional character\n",
        "context1 =  \"\"\" Dr. Ananya Verma, a legendary Indian physicist born\n",
        "in Kolkata in 1960, has made significant contributions to theoretical physics.\n",
        " Her achievements include the discovery of the Bose–Verma condensate, formulation\n",
        "  of quantum entanglement theorems, and resolution of the Verma–Hawking black hole paradox.\n",
        "  Dr. Verma’s brilliance has earned her praise from fellow scientists,\n",
        " and her legacy continues to inspire generations of physicists worldwide. \"\"\"\n",
        "\n",
        "question1 =\"What are few discoveris by Dr. Ananya Verma?\""
      ],
      "metadata": {
        "id": "Pe8hcvHMPO7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "2sKsvZ9yFq7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "id": "DELhooyOYXNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableMap"
      ],
      "metadata": {
        "id": "PwOiK9wHO9gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnableMap(  {\"context\": lambda x: x[\"context\"], \"question\": lambda x: x[\"question\"]}   )   | prompt | llm | StrOutputParser()\n",
        "chain"
      ],
      "metadata": {
        "id": "nxgs3iDcadqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = {\"context\": lambda x: x[\"context\"], \"question\": lambda x: x[\"question\"]} | prompt | llm | StrOutputParser()\n",
        "chain"
      ],
      "metadata": {
        "id": "23Lt4lCFslXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(  {\"context\":context1,\"question\": question1}  )"
      ],
      "metadata": {
        "id": "XM3FrmVBPTtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Complex - Sequential Chain**\n",
        "**Example :1**"
      ],
      "metadata": {
        "id": "CosDESNdRprY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"\"\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\n",
        "Vieux lot ou contrefaçon !?\"\"\""
      ],
      "metadata": {
        "id": "-PArv5JRQCtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = \"gpt-3.5-turbo\" # This is a chat model\n",
        "llm = ChatOpenAI(temperature=0.9, model=llm_model)"
      ],
      "metadata": {
        "id": "J-bLmgAj8JjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 1: translate to english\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate the following review to english:\"\n",
        "    \"\\n\\n{Review}\"\n",
        ")\n",
        "# chain 1: input= Review and output= English_Review\n",
        "chain_one = first_prompt|llm|StrOutputParser()   # output_key=\"English_Review\""
      ],
      "metadata": {
        "id": "COSVBDl2MS2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_review=chain_one.invoke(review)\n",
        "eng_review"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aagoSDNyQ0kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you summarize the following review in 1 sentence:\"\n",
        "    \"\\n\\n{English_Review}\"\n",
        ")\n",
        "# chain 2: input= English_Review and output= summary\n",
        "chain_two = second_prompt|llm|StrOutputParser()  # output_key=\"summary\""
      ],
      "metadata": {
        "id": "ArNHbpFtM7s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_two.invoke(eng_review)"
      ],
      "metadata": {
        "id": "-_YofRTtHwML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 3: translate to english\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"What language is the following review:\\n\\n{Review}\"\n",
        ")\n",
        "# chain 3: input= Review and output= language\n",
        "chain_three = third_prompt|llm|StrOutputParser() # output_key=\"language\""
      ],
      "metadata": {
        "id": "31MwQfe5NIP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_three.invoke(review)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZmA6QLOXRCzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 4: follow up message\n",
        "fourth_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Write a follow up response to the following \"\n",
        "    \"summary in the specified language:\"\n",
        "    \"\\n\\nSummary: {Summary}\\n\\nLanguage: {language}\"\n",
        ")\n",
        "# chain 4: input= summary, language and output= followup_message\n",
        "chain_four = fourth_prompt|llm|StrOutputParser() # output_key=\"followup_message\"\n"
      ],
      "metadata": {
        "id": "ZZg0eafFNYuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_four.invoke({\"Summary\":'The reviewer is disappointed with the taste and quality of the product, questioning if it is an old batch or counterfeit.',\n",
        "                   \"language\":'French'})"
      ],
      "metadata": {
        "id": "GnoqIPGgIx28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "runnable1 = RunnableParallel({\n",
        "    \"Summary\": chain_one | chain_two,\n",
        "    \"language\": chain_three,\n",
        "   })"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zZpJ7PU9OvoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable1.invoke(review)"
      ],
      "metadata": {
        "id": "78nNNdR-T1jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain= RunnableParallel({\"Summary\": chain_one | chain_two,\"language\": chain_three,}) |  {'followup_message':chain_four}\n"
      ],
      "metadata": {
        "id": "llPSiTUWStLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
        "final_chain.invoke(review) #,config={'callbacks': [ConsoleCallbackHandler()]})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5Eek0zI0VQ5C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
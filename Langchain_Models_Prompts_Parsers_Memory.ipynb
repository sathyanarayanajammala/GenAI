{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathyanarayanajammala/GenAI/blob/main/Langchain_Models_Prompts_Parsers_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQeblWrXV2IQ"
      },
      "source": [
        "# Generative AI and Prompt Engineering\n",
        "## A Program by IISc and TalentSprint\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dl4DrfZNzNz"
      },
      "source": [
        "## **LangChain ü¶úüîó: Models, Prompts, Output Parsers and Memory**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxNRAJTZtvFJ"
      },
      "source": [
        "### Objectives:\n",
        "\n",
        "At the end of the experiment you will be able to understand & use :\n",
        " 1. Direct API call to OpenAI\n",
        " 2. API calls through LangChain:\n",
        "   * Prompts\n",
        "   * Models\n",
        "   * Output parsers\n",
        "   * Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdSwQo5VL9yB"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LTu3ADENPjw"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szWDYDp5NcXi"
      },
      "outputs": [],
      "source": [
        "f = open('/content/openapi_key.txt')\n",
        "api_key = f.read().strip()          # Remove Blank Spaces\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "openai.api_key= os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZhn3CsLN3s9"
      },
      "source": [
        "Note: LLMs do not always produce the same results. When executing the code in your notebook, you may get slightly different answers than the demo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmW_k527N6DI"
      },
      "source": [
        "### **Chat API : OpenAI**\n",
        "\n",
        "Let's start with a direct API call to OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iahlnNAL5hTd"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI()\n",
        "\n",
        "def llm_response(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5qi8MUHOuM2"
      },
      "outputs": [],
      "source": [
        "llm_response(\"What is 1+1?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXYVhDOwRmhV"
      },
      "outputs": [],
      "source": [
        "customer_email = \"\"\"\n",
        "My washing machine stops after 15 minutes. \\\n",
        "Something is clogged in outlet or inlet water pipe. \\\n",
        "I need your help \\\n",
        "right now, buddy!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VDIRcjZR_dX"
      },
      "outputs": [],
      "source": [
        "style = \"\"\"Hindi \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnpu07qTSFdR"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Translate the text \\\n",
        "into a style that is {style}.\n",
        "text: ```{customer_email}```\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTiiLPST6owN"
      },
      "outputs": [],
      "source": [
        "response = llm_response(prompt)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY1GKYRGTAeE"
      },
      "source": [
        "### **Chat API : LangChain**\n",
        "\n",
        "Let's try how we can do the same using LangChain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuzGHElGYj9-"
      },
      "source": [
        "#### **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3Q2eShK4Z2q"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3Ah36pJ41di"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "# This is langchain abstraction for the chatGPT API endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMP7mAQGXRY_"
      },
      "outputs": [],
      "source": [
        "# To control the randomness and creativity of the generated\n",
        "# text by an LLM, use temperature = 0.0\n",
        "chat = ChatOpenAI(temperature = 0.0) # model=llm_model\n",
        "chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieZQLMeUYhXs"
      },
      "source": [
        "#### **Prompt template**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC6fRpIuYgCO"
      },
      "outputs": [],
      "source": [
        "template_s = \"\"\"Translate the text \\\n",
        "into {style1}.\\\n",
        "text: ```{text1}```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov-W4j37bT7v"
      },
      "source": [
        "we can now repeadedly use this template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U_WlwjlY1wZ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "#from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWJk1Y56Zm0n"
      },
      "outputs": [],
      "source": [
        "prompt_template.messages[0].prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV6xoQqMZudT"
      },
      "outputs": [],
      "source": [
        "prompt_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8ZzoWzgZ4VE"
      },
      "outputs": [],
      "source": [
        "customer_style = \"\"\"Hindi \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU8wb-z8Z-c6"
      },
      "outputs": [],
      "source": [
        "customer_email = \"\"\"\n",
        "My washing machine stops after 15 minutes. \\\n",
        "Something is clogged in outlet or inlet water pipe. \\\n",
        "I need your help \\\n",
        "right now, buddy!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3jRvkG6aCNK"
      },
      "outputs": [],
      "source": [
        "customer_messages = prompt_template.format_messages(\n",
        "                    style1=customer_style,\n",
        "                    text1=customer_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPTTNr0-aH9A"
      },
      "outputs": [],
      "source": [
        "print(type(customer_messages))\n",
        "print(type(customer_messages[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vze3niKuaVOm"
      },
      "outputs": [],
      "source": [
        "print(customer_messages[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZVtQigefS0G"
      },
      "outputs": [],
      "source": [
        "# Call the LLM to translate to the style of the customer message\n",
        "customer_response = chat.invoke(customer_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb347qlefgyc"
      },
      "outputs": [],
      "source": [
        "print(customer_response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UzyJl8SfrLk"
      },
      "outputs": [],
      "source": [
        "service_reply = \"\"\"‡§á‡§®‡§≤‡•á‡§ü ‡§î‡§∞ ‡§Ü‡§â‡§ü‡§≤‡•á‡§ü ‡§®‡§≤‡•Ä ‡§ñ‡•ã‡§≤‡•á‡§Ç\\\n",
        "‡§î‡§∞ ‡§™‡§æ‡§á‡§™ ‡§∏‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç\\\n",
        "‡§∏‡§æ‡§Æ‡§®‡•á ‡§¶‡§æ‡§π‡§ø‡§®‡•Ä ‡§ì‡§∞ ‡§®‡•Ä‡§ö‡•á ‡§è‡§ï ‡§®‡•ã‡§¨ ‡§≠‡•Ä ‡§ñ‡•ã‡§≤‡•á‡§Ç\\\n",
        "‡§â‡§∏‡•á ‡§≠‡•Ä ‡§∏‡§æ‡§´‡§º ‡§ï‡§∞‡•ã. \\\n",
        "‡§Ü‡§ó‡•á ‡§ï‡•Ä ‡§ï‡§†‡§ø‡§®‡§æ‡§à ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8HLFJlAgqar"
      },
      "outputs": [],
      "source": [
        "service_style = \"\"\"English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-8v0I-EhhRL"
      },
      "outputs": [],
      "source": [
        "service_messages = prompt_template.format_messages(\n",
        "    style1=service_style,\n",
        "    text1=service_reply)\n",
        "\n",
        "print(service_messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Rev6_Tiecm"
      },
      "outputs": [],
      "source": [
        "service_response = chat.invoke(service_messages)\n",
        "print(service_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-CyIL_Z6dOk"
      },
      "source": [
        "### **Output Parsers**\n",
        "\n",
        "Given below is an example of customer review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "916R5_DYgkHU"
      },
      "outputs": [],
      "source": [
        "customer_review_1 = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings:\\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG1rY5Pfglc8"
      },
      "source": [
        "From above customer review: we want to get information as given below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYjp0INI6g5T"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"gift\": True,\n",
        "  \"delivery_days\": 2,\n",
        "  \"price_value\": \"slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtRhY7vv6jo8"
      },
      "outputs": [],
      "source": [
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift or present for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGpGLLxLbjoK"
      },
      "outputs": [],
      "source": [
        "customer_review_2 = \"\"\"\\\n",
        "This vacuum cleaner is absolutely fantastic. It comes with four different modes: light suction, medium breeze,\\\n",
        " strong wind, and cyclone power. It was delivered within three days, just in time for my husband's birthday surprise.\\\n",
        "  I believe he was really impressed by it. Up to now, I've been the only one operating it, and I've been using it\\\n",
        "   regularly to tidy up the floors in our home. It does cost a bit more than other vacuum cleaners on the market,\\\n",
        "    but in my opinion, it's totally worth the investment considering its extra functionalities.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNnDQGzR6m5j"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
        "print(prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pOTyxKn6pyl"
      },
      "outputs": [],
      "source": [
        "messages = prompt_template.format_messages(text=customer_review_1)\n",
        "chat = ChatOpenAI(temperature=0.0)\n",
        "response = chat.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moHN5KrA6r-P"
      },
      "outputs": [],
      "source": [
        "type(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvos0gSi6t-y"
      },
      "outputs": [],
      "source": [
        "# You will get an error by running this line of code\n",
        "# because'gift' is not a dictionary\n",
        "# 'gift' is a string\n",
        "response.content.get('gift')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf3bgzsf7pgP"
      },
      "source": [
        "#### **Parse the LLM output string into a Python dictionary**::\n",
        "[Structured output parser](https://python.langchain.com/docs/modules/model_io/output_parsers/types/structured)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVKZvNeo7vPj"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-N3phWb7wDm"
      },
      "outputs": [],
      "source": [
        "gift_schema = ResponseSchema(name=\"gift\",\n",
        "                             description=\"Was the item purchased\\\n",
        "                             as a gift for someone else? \\\n",
        "                             Answer True if yes,\\\n",
        "                             False if not or unknown.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhaTwYdb71i0"
      },
      "outputs": [],
      "source": [
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
        "                                      description=\"How many days\\\n",
        "                                      did it take for the product\\\n",
        "                                      to arrive? If this \\\n",
        "                                      information is not found,\\\n",
        "                                      output -1.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QCLfwzB76Pb"
      },
      "outputs": [],
      "source": [
        "price_value_schema = ResponseSchema(name=\"price_value\",\n",
        "                                    description=\"Extract any\\\n",
        "                                    sentences about the value or \\\n",
        "                                    price, and output them as a \\\n",
        "                                    comma separated Python list.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnOQzG8a79HG"
      },
      "outputs": [],
      "source": [
        "response_schemas = [gift_schema,\n",
        "                    delivery_days_schema,\n",
        "                    price_value_schema]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NuJnm-_8CHr"
      },
      "outputs": [],
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzzoaiHL8Fx7"
      },
      "outputs": [],
      "source": [
        "format_instructions = output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZjCTE0w8Il_"
      },
      "outputs": [],
      "source": [
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgONpKwM8RsQ"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(template=review_template)\n",
        "\n",
        "messages = prompt.format_messages(text=customer_review_1,\n",
        "                                format_instructions=format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKhPuygo8UkG"
      },
      "outputs": [],
      "source": [
        "print(messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDnQPFwM8WPY"
      },
      "outputs": [],
      "source": [
        "response = chat.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-dJkzLm8YFE"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue3bhEUO8Z76"
      },
      "outputs": [],
      "source": [
        "output_dict = output_parser.parse(response.content)\n",
        "output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQC4fFvG8hVv"
      },
      "outputs": [],
      "source": [
        "type(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi17NJo-8gJd"
      },
      "outputs": [],
      "source": [
        "output_dict.get('delivery_days')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evNdTh0U-auh"
      },
      "source": [
        "\n",
        "\n",
        "### **LangChain: Memory**\n",
        "\n",
        "LangChain can help in building better chatbots, or have\n",
        "an LLM with more effective chats by better managing\n",
        "what it remembers from the conversation you've had so far.\n",
        "\n",
        "* [ConversationBufferMemory](https://python.langchain.com/docs/modules/memory/types/buffer)\n",
        "* [ConversationBufferWindowMemory](https://python.langchain.com/docs/modules/memory/types/buffer_window):  It only uses the last K interactions.\n",
        "* [ConversationTokenBufferMemory](https://python.langchain.com/docs/modules/memory/types/token_buffer): It uses token length rather than number of interactions to determine when to flush interactions.\n",
        "* [ConversationSummaryMemory](https://python.langchain.com/docs/modules/memory/types/summary) : This type of memory creates a summary of the conversation over time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zZZox0PBECe"
      },
      "source": [
        "#### **ConversationBufferMemory**\n",
        "##### **[Customizing Conversational Memory](https://python.langchain.com/docs/modules/memory/conversational_customization)**\n",
        "\n",
        "The **ConversationChain** is a class from the LangChain library that facilitates having a conversation and loading context from memory.\n",
        "\n",
        "The primary purpose of the ConversationChain is to enable conversational interactions with a language model (LLM) while maintaining context across multiple turns.\n",
        "\n",
        "It‚Äôs particularly useful for chatbots, virtual assistants, or any application where maintaining conversation history matters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujh1qsGG_3ev"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGtO-pr0_73-"
      },
      "outputs": [],
      "source": [
        "llm_model=\"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True # False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOzPymY6Adee"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"Hi,I am Ramendra\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_5hJ61cAozK"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is 6 divided by 2?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e6UpI__AvHq"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWkaURxMAxf3"
      },
      "outputs": [],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbp14UAyAzRD"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL_07qjxDCkl"
      },
      "source": [
        "How langchain keeps adding the conversation in memory?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt1Ruwq8A1DB"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7lvyvGWBJV6"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCrWSexsBLHC"
      },
      "outputs": [],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRlIY-9sBM8U"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBBu5-qhBPQu"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
        "                    {\"output\": \"Cool\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-cRyFB2BWco"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBf7fcLRE2dH"
      },
      "source": [
        "#### **ConversationBufferWindowMemory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eQjXkleFCoY"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRJWAEMhFDVB"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferWindowMemory(k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNf37MZKFGX3"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})\n",
        "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
        "                    {\"output\": \"Cool\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY9eORpjFKZ7"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kXvjHe6FMgb"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=False # True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOs7XomrFa9Y"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"Hi,I am Ramendra\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMF-tHyrFi-L"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is 1+1?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUOaMXT8E7YX"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD9INhNhF_vh"
      },
      "source": [
        "#### **ConversationTokenBufferMemory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA7y4f_tGFWG"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq5HwBlAGIwz"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationTokenBufferMemory\n",
        "llm_model=\"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF9itwR7GDt8"
      },
      "outputs": [],
      "source": [
        "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=20)# Different llm has different ways of counting tokens\n",
        "memory.save_context({\"input\": \"AI is what?!\"},\n",
        "                    {\"output\": \"Amazing!\"})\n",
        "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
        "                    {\"output\": \"Beautiful!\"})\n",
        "memory.save_context({\"input\": \"Chatbots are what?\"},\n",
        "                    {\"output\": \"Charming!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHRnJ0HEGL6o"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8PZx9d0HRVD"
      },
      "source": [
        "#### **ConversationSummaryMemory**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23LbZFGUHNa1"
      },
      "source": [
        "In the conversation summary buffer memory, instead of limiting the memory to a fixed number\n",
        "of tokens based on the most recent utterances or a fixed number of conversational exchanges, it uses an LLM to write a summary of the conversation so far,\n",
        "and let that be the memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpzJ34SDH3vE"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationSummaryBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX5xSqc6H2wx"
      },
      "outputs": [],
      "source": [
        "# create a long string\n",
        "schedule = \"There is a meeting at 8am with your product team. \\\n",
        "You will need your powerpoint presentation prepared. \\\n",
        "9am-12pm have time to work on your LangChain \\\n",
        "project which will go quickly because Langchain is such a powerful tool. \\\n",
        "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
        "from over an hour away to meet you to understand the latest in AI. \\\n",
        "Be sure to bring your laptop to show the latest LLM demo.\"\n",
        "\n",
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
        "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
        "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
        "                    {\"output\": \"Cool\"})\n",
        "memory.save_context({\"input\": \"What is on the schedule today?\"},\n",
        "                    {\"output\": f\"{schedule}\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4emgbogH70a"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezgBgIjuH-Km"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71CDdUzRH_wN"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What would be a good demo to show?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBp8_WUEIBZq"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathyanarayanajammala/GenAI/blob/main/Additional_NB_01_LangChain_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI and Prompt Engineering\n",
        "## A programme by IISc and TalentSprint\n",
        "### Additional Notebook: LangChain Agents ü¶úüîó\n",
        "\n",
        "(Ungraded)"
      ],
      "metadata": {
        "id": "zsbKS8XFt5iF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* understand the difference between a tool and an agent\n",
        "* use Agents in LangChain\n",
        "* add different tools to your agent such as wikipedia tool, math calculator, google search, python executor, etc\n",
        "* define your own tool to add to an agent"
      ],
      "metadata": {
        "id": "ShQ6pYPntmFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Information"
      ],
      "metadata": {
        "id": "vdxzq_iS8Zn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **What are Tools?**\n",
        ">\n",
        "> Tools are helpful and act as a interface that an agent, a chain, or a chat model / LLM (Large Language Model) can use to ineract with the world. For e.g., Tools can be Search tool like SerpAPI, Google search etc.,. Given a list of tools and prompt, an LLM can request that one or more tools be invoked with appropriate arguments.\n",
        "\n",
        "> **Whar are Agents?**\n",
        ">\n",
        "> In LangChain, an ‚Äú**Agent**‚Äù is an AI entity that interacts with various ‚Äú**Tools**‚Äù to perform tasks or answer queries. Tools are essentially functions that extend the agent's capabilities by allowing it to perform specific actions, like retrieving the current time or accessing an external database.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Uo1YNVICwjpKm6PTZCdRGpuSKvTGL6q6' width=800px>"
      ],
      "metadata": {
        "id": "hOJ3gRS-zxe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic code to create an agent in LangChain involves:\n",
        "- defining tools,\n",
        "- loading a template for ReAct prompting,\n",
        "- initializing a language model, and\n",
        "- creating an agent that uses ReAct prompting and language model.\n",
        "- The agent is then executed using an **`AgentExecutor`**, which *manages the interaction between the agent and the tools*.\n",
        "\n",
        "This setup allows for dynamic and context-aware responses, enabling the AI to reason and take actions in a structured manner.\n"
      ],
      "metadata": {
        "id": "2neIj7n581Js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ReAct Prompting**"
      ],
      "metadata": {
        "id": "33eMbDwsxEhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will use an agent that will implement the [ReAct](https://react-lm.github.io/) logic.\n",
        "\n",
        "**ReAct** overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API or any other APIs, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces.\n",
        "\n",
        "<center><img src='https://react-lm.github.io/files/diagram.png' width=1000px></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "6JyF1P83iOKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **ReAct prompt** consists of few-shot task-solving trajectories, with human-written text reasoning traces and actions, as well as environment observations in response to actions.\n",
        "\n",
        "ReAct prompting is intuitive and flexible to design, and achieves state-of-the-art few-shot performances across a variety of tasks, from question answering to online shopping.\n",
        "<br><br>\n",
        "\n",
        "<img src='https://react-lm.github.io/files/hotpotqa.png' width=1200px>"
      ],
      "metadata": {
        "id": "x-N7k93Vi_2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample ReAct prompt for Agents**\n",
        "\n",
        "```\n",
        "Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\n",
        "```\n",
        "\n",
        "The variables that must be passed as arguments to this prompt are as follows.\n",
        "\n",
        "- **tools:** A description of the tool, including a description of the tool, input variables for each tool, and their description.\n",
        "- **input:** question input by agent\n",
        "- **tools_name:** Names of tools that the agent can use\n",
        "- **agent_scratchpad:** The agent does not call a tool just once to get the desired answer, but has a structure that calls tools repeatedly until the desired answer is obtained. Each time you call a tool, what the previous call was like, information about the previous call, and the result are stored in this field. It is used to keep track of the agent's thoughts or actions during the execution of the program and let the agent continue its thought process.\n",
        "\n",
        "The variable values in the prompt are filled in automatically, so there is no place to modify them. As for the prompt, you can also use the example that has already been written. If you just want to improve the agent‚Äôs performance, you can modify this prompt.\n"
      ],
      "metadata": {
        "id": "lRuwSVAv9GGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prompt guides the agent‚Äôs operation mechanism.\n",
        "\n",
        "```\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "```\n",
        "\n",
        "At the ***Thought*** stage, the agent uses llm to think about what action to take to get the answer to the question, and ***Action*** decides which tool to use, and ***Action Input*** creates a new question queried by the tool. And finally, ***Observation*** saves the results in the tool called by Action.\n",
        "\n",
        "Through this sequence, the Agent executes [Thought --> Action --> Action Input --> Observation], saves the result in `agent_scratchpad`, and repeats this process until the desired answer is obtained.\n",
        "\n",
        "Once you have created a prompt, create an agent using this prompt, and create and call an agent executor using this agent.\n",
        "\n",
        "If an agent makes a decision about an incoming question and executes a tool, a subject is needed to repeatedly run the agent through this process until an answer is obtained. The agent executor plays this role."
      ],
      "metadata": {
        "id": "gmWmXF5S-6KT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Agent execution detailed structure**\n",
        "\n",
        "The diagram below shows this execution structure graphically.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1c7PXH8bFLIsUawtNes99Ma6BQT24SYXR' width=700px>\n",
        "\n",
        "When a <font color='#117799'>Question</font> comes in, insert this question into the <font color='#339955'>Agent Prompt</font> created earlier and deliver it to the agent.\n",
        "\n",
        "To answer a question, the agent refers to the guide in the agent prompt and creates the necessary question (corresponds to <font color='#993333'>Question 1</font>: ***Action Input***) through the thought process. After receiving the answer (corresponding to <font color='#993333'>Answer 1</font>: ***Observation***) by calling the <font color='#339955'>Tool</font> (corresponding to ***Action***) that selected the question, append the answer to `agent_scratchpad` of the existing agent prompt.\n",
        "\n",
        "The agent executor passes this agent prompt back to the agent, creates <font color='#993333'>Question 2</font> in the same order, receives the answer <font color='#993333'>Answer2</font>, and similarly appends it to the existing agent prompt.\n",
        "\n",
        "When `agent_executor` passes this prompt to the agent again, if enough information necessary for the answer has been collected, the agent generates an answer based on the information in the prompt and returns the <font color='#117799'>Final Answer</font>."
      ],
      "metadata": {
        "id": "9_rCR65U_3lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install required dependencies"
      ],
      "metadata": {
        "id": "WeXRnNMfnFqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip -q install openai\n",
        "!pip -q install langchain-core\n",
        "!pip -q install langchain-community\n",
        "!pip -q install sentence-transformers\n",
        "!pip -q install langchain-huggingface\n",
        "!pip -q install langchain-experimental\n",
        "!pip -q install langchainhub\n",
        "!pip -q install langchain-openai\n",
        "\n",
        "# for wikipedia as a tool\n",
        "!pip -q install -U wikipedia\n",
        "\n",
        "# for google-search as a tool\n",
        "!pip -q install google-search-results"
      ],
      "metadata": {
        "id": "D_6LHD3pwpDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required packages"
      ],
      "metadata": {
        "id": "T0sgU1wiq7Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "import openai\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import hub\n",
        "from langchain.agents import load_tools, create_react_agent, AgentExecutor\n",
        "from langchain.tools.render import render_text_description\n",
        "from langchain_community.utilities import SerpAPIWrapper"
      ],
      "metadata": {
        "id": "b8NxNFPDxSIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Provide your OpenAI API key**"
      ],
      "metadata": {
        "id": "dMBDqFT0kkgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your OpenAI key to Colab Secrets with name 'OPENAI_KEY' then run this cell\n",
        "\n",
        "api_key = userdata.get('OPENAI_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "openai.api_key= os.getenv('OPENAI_API_KEY')\n",
        "del api_key"
      ],
      "metadata": {
        "id": "V6qYqEdPXstB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load your Language Model**"
      ],
      "metadata": {
        "id": "FzOLexr_cLrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# We are going to use this language model as the reasoning engine of the agent to connect to other data sources and perform computation\n",
        "# so we want this reasoning engine to be as presice as possible.\n",
        "# Hence, temperature is set to zero to get rid of any randomness."
      ],
      "metadata": {
        "id": "ZHd51H2ISEyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"How to learn programming? Give 5 points.\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tItT3ZcC_or",
        "outputId": "04dfbe6e-9f0d-4908-ffff-931e1dd65bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning programming can be an exciting and rewarding journey. Here are five key points to help you get started:\n",
            "\n",
            "1. **Choose a Programming Language**: Start with a beginner-friendly language such as Python, JavaScript, or Ruby. These languages have extensive resources, community support, and are widely used in various applications.\n",
            "\n",
            "2. **Utilize Online Resources**: Take advantage of online platforms like Codecademy, freeCodeCamp, Coursera, or edX. These platforms offer structured courses, tutorials, and exercises that can help you learn at your own pace.\n",
            "\n",
            "3. **Practice Regularly**: Consistent practice is crucial for mastering programming. Work on small projects, solve coding challenges on platforms like LeetCode or HackerRank, and contribute to open-source projects to apply what you‚Äôve learned.\n",
            "\n",
            "4. **Join a Community**: Engage with other learners and experienced programmers through forums like Stack Overflow, Reddit, or local coding meetups. Participating in a community can provide support, motivation, and valuable feedback.\n",
            "\n",
            "5. **Build Projects**: Start creating your own projects, no matter how simple. Building real-world applications helps reinforce your learning, improves problem-solving skills, and gives you a portfolio to showcase your work.\n",
            "\n",
            "By following these steps, you'll develop a solid foundation in programming and be well on your way to becoming proficient.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain: Agents**"
      ],
      "metadata": {
        "id": "n446yf5pGQKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Built-in LangChain [tools](https://python.langchain.com/v0.2/docs/integrations/tools/)\n",
        "\n",
        "Here, we will learn how to use\n",
        "\n",
        "1. Wikipedia tool\n",
        "2. LLM Math tool\n",
        "3. Combine two or more tools\n",
        "4. Google Search Engine tool\n",
        "5. Python Agent\n",
        "6. Define your own tool"
      ],
      "metadata": {
        "id": "tpYBLkfggP2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Wikipedia tool**\n",
        "\n",
        "`wikipedia` tool is an api that connects with wikipedia allowing to run search queries against wikipedia and get back the results."
      ],
      "metadata": {
        "id": "b2fcOZptfOgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load tools**\n",
        "\n",
        "`load_tools`: Load tools based on their name.\n",
        "\n",
        "Tools allow agents to interact with various resources and services like APIs, databases, file systems, etc.\n",
        "\n",
        "To know more about `load_tools` API, refer [here](https://api.python.langchain.com/en/latest/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html)."
      ],
      "metadata": {
        "id": "NZSFuV8GJKOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "# Initialize tools\n",
        "tools = load_tools([\"wikipedia\"])\n",
        "\n",
        "tools"
      ],
      "metadata": {
        "id": "6PhC1fyVfPbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76921bbf-4324-484c-898d-14c3a12da926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000))]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.render import render_text_description\n",
        "\n",
        "# Render tools description\n",
        "render_text_description(tools)"
      ],
      "metadata": {
        "id": "CrDAKkGxgBTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "901ff4fd-f3b9-4666-806d-fb4dee1c2b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pull ReAct Prompt**"
      ],
      "metadata": {
        "id": "XwM8N0lVDExU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull the ReAct style prompt template from the hub ; ReAct = Reason and Action\n",
        "# https://smith.langchain.com/hub/hwchase17/react\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml7TNyUQDNx5",
        "outputId": "81575a19-598c-4331-e969-dd58531d7267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIus6BVolXTU",
        "outputId": "a0639e28-08ca-419e-e1df-38a13e88fb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Create [ReAct](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/react/) Agent**\n",
        "\n",
        "`create_react_agent()` creates a ReAct agent using the specified model (llm), tools (tools), and prompt template (prompt)."
      ],
      "metadata": {
        "id": "7rPwxZmWri4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ReAct agent using the create_react_agent function\n",
        "\n",
        "from langchain.agents import create_react_agent\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,                         # LLM to use as the agent\n",
        "    tools=tools,                     # Tools this agent has access to\n",
        "    prompt=prompt,                   # The prompt to use\n",
        "    stop_sequence=True,              # stop_sequence=True ensures that the agent stops processing when it reaches a predefined\n",
        "                                     # stopping point in the conversation. If True, adds a stop token of ‚ÄúObservation:‚Äù to avoid hallucinates.\n",
        ")"
      ],
      "metadata": {
        "id": "Zv_GIWlvEw1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor from the agent and tools\n",
        "\n",
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent,         # Agent to use\n",
        "    tools=tools,         # Tools to use\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "nvO6LiHRFKAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent with a test query\n",
        "\n",
        "response = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Which of them was built first - Eiffel Tower or Taj Mahal?\"\n",
        "    }\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf0SG3ZeFe5r",
        "outputId": "61667293-1653-4293-b430-bab1855aee8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo answer the question, I need to find out the construction dates of both the Eiffel Tower and the Taj Mahal. I will look up each structure to determine which one was built first. \n",
            "\n",
            "Action: wikipedia  \n",
            "Action Input: \"Eiffel Tower\"  \u001b[0m\u001b[36;1m\u001b[1;3mPage: Eiffel Tower\n",
            "Summary: The Eiffel Tower (  EYE-f…ôl; French: Tour Eiffel [tu Å …õf…õl] ) is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower from 1887 to 1889.\n",
            "Locally nicknamed \"La dame de fer\" (French for \"Iron Lady\"), it was constructed as the centerpiece of the 1889 World's Fair, and to crown the centennial anniversary of the French Revolution. Although initially criticised by some of France's leading artists and intellectuals for its design, it has since become a global cultural icon of France and one of the most recognisable structures in the world.  The tower received 5,889,000 visitors in 2022. The Eiffel Tower is the most visited monument with an entrance fee in the world: 6.91 million people ascended it in 2015. It was designated a monument historique in 1964, and was named part of a UNESCO World Heritage Site (\"Paris, Banks of the Seine\") in 1991.\n",
            "The tower is 330 metres (1,083 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest human-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure in the world to surpass both the 200-metre and 300-metre mark in height. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\n",
            "The tower has three levels for visitors, with restaurants on the first and second levels. The top level's upper platform is 276 m (906 ft) above the ground‚Äîthe highest observation deck accessible to the public in the European Union. Tickets can be purchased to ascend by stairs or lift to the first and second levels. The climb from ground level to the first level is over 300 steps, as is the climb from the first level to the second, making the entire ascent a 600 step climb. Although there is a staircase to the top level, it is usually accessible only by lift. On this top, third level is a private apartment built for Gustave Eiffel's private use. He decorated it with furniture by Jean Lachaise and invited friends such as Thomas Edison.\n",
            "\n",
            "\n",
            "\n",
            "Page: Eiffel Tower replicas and derivatives\n",
            "Summary: As one of the most iconic and recognizable structures in the world, the Eiffel Tower, completed in 1889, has been the inspiration for the creation of over 50 similar towers around the world. Most are not exact replicas, though there are many that resemble it closely, while others look slightly different. The Eiffel Tower has also inspired other towers that are not close resembling replicas and therefore are not listed here, for example the Blackpool Tower.\n",
            "\n",
            "Page: List of the 72 names on the Eiffel Tower\n",
            "Summary: On the Eiffel Tower, 72 names of French men (scientists, engineers, and mathematicians) are engraved in recognition of their contributions. Gustave Eiffel chose this \"invocation of science\" because of his concern over the protests against the tower, and chose names of those who had distinguished themselves since 1789. The engravings are found on the sides of the tower under the first balcony, in letters about 60 cm (24 in) tall, and were originally painted in gold. The engraving was painted over at the beginning of the 20th century and restored in 1986‚Äì87 by Soci√©t√© Nouvelle d'exploitation de la Tour Eiffel, the company that the city of Paris contracts to operate the Tower. The repainting of 2010‚Äì11 restored the letters to their original gold colour. There are also names of the engineers who helped build the Tower and design its architecture on a plaque on the top of the Tower, where a laboratory was \u001b[0m\u001b[32;1m\u001b[1;3mI have found that the Eiffel Tower was completed in 1889. Now, I need to find out the construction date of the Taj Mahal to compare the two.\n",
            "\n",
            "Action: wikipedia  \n",
            "Action Input: \"Taj Mahal\"  \u001b[0m\u001b[36;1m\u001b[1;3mPage: Taj Mahal\n",
            "Summary: The Taj Mahal ( TAHJ m…ô-HAHL, TAHZH -‚Å†, Hindi: [taÀêd í Ààm…õ…¶(…õ)l]; lit.‚Äâ'Crown of the Palace') is an ivory-white marble mausoleum on the right bank of the river Yamuna in Agra, Uttar Pradesh, India. It was commissioned in 1631 by the fifth Mughal emperor, Shah Jahan (r.‚Äâ1628‚Äì1658) to house the tomb of his beloved wife, Mumtaz Mahal; it also houses the tomb of Shah Jahan himself. The tomb is the centrepiece of a 17-hectare (42-acre) complex, which includes a mosque and a guest house, and is set in formal gardens bounded on three sides by a crenellated wall.\n",
            "Construction of the mausoleum was completed in 1648, but work continued on other phases of the project for another five years. The first ceremony held at the mausoleum was an observance by Shah Jahan, on 6 February 1643, of the 12th anniversary of the death of Mumtaz Mahal. The Taj Mahal complex is believed to have been completed in its entirety in 1653 at a cost estimated at the time to be around ‚Çπ5 million, which in 2023 would be approximately ‚Çπ35 billion (US$77.8 million).\n",
            "The building complex incorporates the design traditions of Indo-Islamic and Mughal architecture. It employs symmetrical constructions with the usage of various shapes and symbols. While the mausoleum is constructed of white marble inlaid with semi-precious stones, red sandstone was used for other buildings in the complex similar to the Mughal era buildings of the time. The construction project employed more than 20,000 workers and artisans under the guidance of a board of architects led by Ustad Ahmad Lahori, the emperor's court architect.\n",
            "The Taj Mahal was designated as a UNESCO World Heritage Site in 1983 for being \"the jewel of Islamic art in India and one of the universally admired masterpieces of the world's heritage\". It is regarded as one of the best examples of Mughal architecture and a symbol of Indian history. The Taj Mahal is a major tourist attraction and attracts more than five million visitors a year. In 2007, it was declared a winner of the New 7 Wonders of the World initiative.\n",
            "\n",
            "\n",
            "\n",
            "Page: Taj Mahal Palace Hotel\n",
            "Summary: The Taj Mahal Palace is a heritage, five-star, luxury hotel in the Colaba area of Mumbai, Maharashtra, India, situated next to the Gateway of India. Built in the Indo-Saracenic style, it opened in 1903 as the Taj Mahal Hotel and has historically often been known simply as \"The Taj\". The hotel is named after the Taj Mahal, which is located in the city of Agra approximately 1,050 kilometres (650 mi) from Mumbai. It has been considered one of the finest hotels in the East since the time of the British Raj. The hotel was one of the main targets in the 2008 Mumbai attacks.\n",
            "Part of the Taj Hotels Resorts and Palaces, the hotel has 560 or 600 rooms and 44 suites and is considered the flagship property of the group; it employs 1,600 staff. The hotel is made up of two different structures: the Taj Mahal Palace and the Tower, which are historically and architecturally distinct from each other (the Taj Mahal Palace was built in 1903; the Tower was opened in 1972).\n",
            "The hotel has received many notable guests, from presidents to captains of industry and movie stars. Rattanbai Petit, wife of Muhammad Ali Jinnah, spent the last days of her life in one of the suites of the hotel, and eventually died there in 1929, at the age of 29.\n",
            "\n",
            "\n",
            "\n",
            "Page: Taj Mahal (musician)\n",
            "Summary: Henry St. Claire Fredericks Jr. (born May 17, 1942), better known by his stage name Taj Mahal, is an American blues musician. He plays the guitar, piano, banjo, harmonica, and many other instruments, often incorporating elements of world music into his work. Mahal has done much to reshape the definition and scope of blues music over the course of his more than 50-year career by fusing it with nontraditional forms, including sounds from the Caribbean, Africa, India, Hawaii, and the South Pacific.\u001b[0m\u001b[32;1m\u001b[1;3mI have found that the Taj Mahal was completed in 1648, with the entire complex finished by 1653. Now I can compare the construction dates of both structures.\n",
            "\n",
            "The Eiffel Tower was completed in 1889, while the Taj Mahal was completed in 1648. Therefore, the Taj Mahal was built first.\n",
            "\n",
            "Final Answer: The Taj Mahal was built first, completed in 1648, while the Eiffel Tower was completed in 1889.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent with a test query\n",
        "\n",
        "response = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Tom M. Mitchell is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). What book did he write?\"\n",
        "    }\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj7qjbzyz-Y7",
        "outputId": "4eff008f-5243-414e-b0d8-b6947b19ccf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out what book Tom M. Mitchell wrote. \n",
            "Action: wikipedia\n",
            "Action Input: \"Tom M. Mitchell book\"\u001b[0m\u001b[36;1m\u001b[1;3mPage: Tom Clancy\n",
            "Summary: Thomas Leo Clancy Jr. (April 12, 1947 ‚Äì October 1, 2013) was an American novelist. He is best known for his technically detailed espionage and military-science storylines set during and after the Cold War. Seventeen of his novels have been bestsellers and more than 100 million copies of his books have been sold. His name was also used on screenplays written by ghostwriters, nonfiction books on military subjects occasionally with co-authors, and video games. He was a part-owner of his hometown Major League Baseball team, the Baltimore Orioles, and vice-chairman of their community activities and public affairs committees.\n",
            "Originally an insurance agent, Clancy launched his literary career in 1984 when he sold his first military thriller novel The Hunt for Red October for $5,000 published by the small academic Naval Institute Press of Annapolis, Maryland.\n",
            "His works The Hunt for Red October (1984), Patriot Games (1987), Clear and Present Danger (1989), and The Sum of All Fears (1991) have been turned into commercially successful films. Tom Clancy's works also inspired games such as the Ghost Recon, Rainbow Six, The Division, and Splinter Cell series. Since Clancy's death in 2013, the Jack Ryan series has been continued by his family estate through a series of authors.\n",
            "\n",
            "Page: William M. Mitchell\n",
            "Summary: William M. Mitchell (c. 1826 ‚Äì c. 1879) was an American writer, minister and abolitionist who worked on the Underground Railroad. He is said to be the only writer who wrote about the railroad while it was still illegal.\n",
            "\n",
            "Page: Victoria Coren Mitchell\n",
            "Summary: Victoria Elizabeth Coren Mitchell (n√©e Coren; born (1972-08-18)18 August 1972) is a British writer, TV presenter and professional poker player. She writes weekly columns for The Daily Telegraph and has hosted the BBC television quiz show Only Connect since 2008.\u001b[0m\u001b[32;1m\u001b[1;3mThe search did not yield relevant information about Tom M. Mitchell or his book. I need to refine my search to focus specifically on Tom M. Mitchell and his works.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: \"Tom M. Mitchell\"\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mPage: Tom M. Mitchell\n",
            "Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past President of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.\n",
            "\n",
            "Page: Ensemble learning\n",
            "Summary: In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.\n",
            "Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.\n",
            "\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI have found the relevant information about Tom M. Mitchell. He is the author of the textbook \"Machine Learning.\" \n",
            "\n",
            "Final Answer: Tom M. Mitchell wrote the textbook \"Machine Learning.\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Tom M. Mitchell is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). What book did he write?',\n",
              " 'output': 'Tom M. Mitchell wrote the textbook \"Machine Learning.\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. LLM Math tool**\n",
        "\n",
        "`llm-math` tool is a chain itself which uses a language model in conjuction with a calculater to do math problems."
      ],
      "metadata": {
        "id": "pgcSMgt1tZ__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"llm-math\"], llm=llm)\n",
        "\n",
        "tools"
      ],
      "metadata": {
        "id": "9f2KZZvttdJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f6d462-f664-4348-dcfc-f96b461a59fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x791fe8af3700>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x791fe8ce8c70>, root_client=<openai.OpenAI object at 0x791fe8af2c50>, root_async_client=<openai.AsyncOpenAI object at 0x791fe8af2a70>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x791fe8af3700>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x791fe8ce8c70>, root_client=<openai.OpenAI object at 0x791fe8af2c50>, root_async_client=<openai.AsyncOpenAI object at 0x791fe8af2a70>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))>)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "render_text_description(tools)"
      ],
      "metadata": {
        "id": "Fr2nbhoexV-q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6384e398-cb2d-47c6-979b-a6a18fc99af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Calculator(*args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ReAct agent using the create_react_agent function\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        "    stop_sequence=True,\n",
        ")"
      ],
      "metadata": {
        "id": "54eE928UHN4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor from the agent and tools\n",
        "\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "6BdKUEbdHN4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent with a test query\n",
        "\n",
        "response = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"What is 10% of 500?\"\n",
        "    }\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3f1f4f-2e5f-4844-b052-8b5b0e48e246",
        "id": "slbr_JP6HN4y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find 10% of 500, I need to calculate 10/100 multiplied by 500. \n",
            "Action: Calculator\n",
            "Action Input: 10/100 * 500\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 50.0\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: 50.0\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent with a test query\n",
        "\n",
        "response = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"What is 20% of 500?\"\n",
        "    }\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dS5Cd28Vdf3",
        "outputId": "bdf59fd2-c7b4-4c1e-ec1c-5f8905a9b534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find 20% of 500, I need to calculate 20/100 multiplied by 500. \n",
            "Action: Calculator\n",
            "Action Input: 20/100 * 500\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 100.0\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: 100.0\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Combining two or more tools**"
      ],
      "metadata": {
        "id": "xxwg1URmy90W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"llm-math\", \"wikipedia\"], llm=llm)\n",
        "print(render_text_description(tools))"
      ],
      "metadata": {
        "id": "EsEL_DfyzZrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad70cb32-9426-4cd9-c8c5-24ccb89006ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculator(*args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n",
            "wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ReAct agent using the create_react_agent function\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        "    stop_sequence=True,\n",
        ")"
      ],
      "metadata": {
        "id": "W-D49rMmV7ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor from the agent and tools\n",
        "\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "YkptulRcV7fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = \"Tom M. Mitchell is an American computer scientist \\\n",
        "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
        "what book did he write?\"\n",
        "\n",
        "question2 = \"What is 20% of 500?\""
      ],
      "metadata": {
        "id": "c9MYQ0h8zwcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke({\"input\": question1})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu7RzzLE7qlW",
        "outputId": "f43bd7b3-69e3-4cd3-d985-ee15cf7f0e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out what book Tom M. Mitchell has written. Since he is a notable figure in computer science, there may be information available on Wikipedia about his works. \n",
            "\n",
            "Action: wikipedia  \n",
            "Action Input: \"Tom M. Mitchell book\"  \u001b[0m\u001b[33;1m\u001b[1;3mPage: Tom Stoltman\n",
            "Summary: Tom Ryan Stoltman (born 30 May 1994) is a British professional strongman competitor, from Invergordon, Scotland. He is a three time winner of the World's Strongest Man in 2021, 2022, and 2024. He also won the national title of Britain's Strongest Man on the same years. Nicknamed \"The Albatross\" due to his sizeable arm span, Stoltman is known for his prowess with the Atlas Stones. In 2020, Stoltman broke the world record for the 5 Atlas Stones (light set) 100‚Äì180 kilograms (220‚Äì397 lb) in just 16.01 seconds; he also holds the world record for the heaviest Atlas stone ever lifted over a 1.22 metres (4.0 ft) bar at 286 kilograms (631 lb).\n",
            "On 20 June 2021, Stoltman won the 2021 World's Strongest Man competition, becoming the first man from Scotland to win the World's Strongest Man and the fifth British person to do so. On 29 May 2022, Stoltman won the 2022 World's Strongest Man, becoming only the second Briton to win two titles (37 years after Geoff Capes) and the first to win back to back titles. In the 2023 World's Strongest Man, he emerged runner up behind Mitchell Hooper, and then in the 2024 World's Strongest Man he reclaimed his title, becoming the only Briton to have won three World's Strongest Man titles.\n",
            "Tom Stoltman is the younger brother of the two-time Europe's Strongest Man and five-time Scotland's Strongest Man, Luke Stoltman, with whom he runs their YouTube channel The Stoltman Brothers.\n",
            "\n",
            "Page: Tom Clancy\n",
            "Summary: Thomas Leo Clancy Jr. (April 12, 1947 ‚Äì October 1, 2013) was an American novelist. He is best known for his technically detailed espionage and military-science storylines set during and after the Cold War. Seventeen of his novels have been bestsellers and more than 100 million copies of his books have been sold. His name was also used on screenplays written by ghostwriters, nonfiction books on military subjects occasionally with co-authors, and video games. He was a part-owner of his hometown Major League Baseball team, the Baltimore Orioles, and vice-chairman of their community activities and public affairs committees.\n",
            "Originally an insurance agent, Clancy launched his literary career in 1984 when he sold his first military thriller novel The Hunt for Red October for $5,000 published by the small academic Naval Institute Press of Annapolis, Maryland.\n",
            "His works The Hunt for Red October (1984), Patriot Games (1987), Clear and Present Danger (1989), and The Sum of All Fears (1991) have been turned into commercially successful films. Tom Clancy's works also inspired games such as the Ghost Recon, Rainbow Six, The Division, and Splinter Cell series. Since Clancy's death in 2013, the Jack Ryan series has been continued by his family estate through a series of authors.\n",
            "\n",
            "Page: William M. Mitchell\n",
            "Summary: William M. Mitchell (c. 1826 ‚Äì c. 1879) was an American writer, minister and abolitionist who worked on the Underground Railroad. He is said to be the only writer who wrote about the railroad while it was still illegal.\u001b[0m\u001b[32;1m\u001b[1;3mI need to refine my search to find specific information about Tom M. Mitchell and his works, as the previous search did not yield relevant results. \n",
            "\n",
            "Action: wikipedia  \n",
            "Action Input: \"Tom M. Mitchell Carnegie Mellon University book\"  \u001b[0m\u001b[33;1m\u001b[1;3mPage: List of Carnegie Mellon University people\n",
            "Summary: This is a list of notable people associated with Carnegie Mellon University in the United States of America.\n",
            "\n",
            "Page: Ted Danson\n",
            "Summary: Edward Bridge Danson III (born December 29, 1947) is an American actor and comedian. He achieved stardom playing the lead character Sam Malone on the NBC sitcom Cheers, for which he received two Primetime Emmy Awards and two Golden Globe Awards. He was further Emmy-nominated for the legal drama Damages (2007‚Äì2010) and the NBC dramedy The Good Place (2016‚Äì2020). He was awarded a star on Hollywood's Walk of Fame in 1999.\n",
            "Danson made his film debut in 1978 in the crime drama The Onion Field. His breakout film role was as Jack Holden in the films Three Men and a Baby (1987) and Three Men and a Little Lady (1990). He also acted in Body Heat (1981), Creepshow (1982), Dad (1989) and Saving Private Ryan (1998).\n",
            "Danson's other leading roles on television include the CBS sitcom Becker (1998‚Äì2004), CBS drama CSI: Crime Scene Investigation (2011‚Äì2015), and CSI: Cyber (2015‚Äì2016). In 2015, he starred in the second season of FX's anthology series Fargo. He has played roles in the HBO comedies Bored to Death (2009‚Äì2011) and Curb Your Enthusiasm (2000‚Äì2024), and the NBC sitcom Mr. Mayor (2021‚Äì2022).\n",
            "Danson is also known for his longtime activism in ocean conservation. In March 2011, he published his first book, Oceana: Our Endangered Oceans and What We Can Do to Save Them which was written with journalist Michael D'Orso. He has been married to actress Mary Steenburgen since 1995.\n",
            "\n",
            "Page: Rayid Ghani\n",
            "Summary: Rayid Ghani (born 1977) is a Distinguished Career Professor in the Machine Learning Department (in the School of Computer Science) and the Heinz College of Information Systems and Public Policy at Carnegie Mellon University. Previously, he was the director of the Center for Data Science and Public Policy, research associate professor in the department of computer science, and a senior fellow at the Harris School of Public Policy at the  University of Chicago. He was also the co-founder of Edgeflip, an analytics startup that grew out of the Obama 2012 Campaign, focused on social media products for non-profits, advocacy groups, and charities. Recently, it was announced that he will be leaving the University of Chicago and joining Carnegie Mellon University's School of Computer Science and Heinz College of Information Systems and Public Policy.\n",
            "Ghani started and runs the Eric & Wendy Schmidt Data Science for Social Good Summer Fellowship. He's also the co-founder of Coleridge Initiative, a nonprofit organization working with governments to ensure that data and evidence is used more effectively for policymaking.\u001b[0m\u001b[32;1m\u001b[1;3mI still haven't found the specific book written by Tom M. Mitchell. I need to search for his name directly to find more relevant information about his publications.\n",
            "\n",
            "Action: wikipedia  \n",
            "Action Input: \"Tom M. Mitchell\"  \u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33;1m\u001b[1;3mPage: Tom M. Mitchell\n",
            "Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past President of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.\n",
            "\n",
            "Page: Ensemble learning\n",
            "Summary: In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.\n",
            "Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.\n",
            "\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI now know that Tom M. Mitchell is the author of the textbook \"Machine Learning.\" \n",
            "\n",
            "Final Answer: Tom M. Mitchell wrote the book \"Machine Learning.\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Tom M. Mitchell is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU)what book did he write?',\n",
              " 'output': 'Tom M. Mitchell wrote the book \"Machine Learning.\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke({\"input\": question2})\n",
        "result"
      ],
      "metadata": {
        "id": "gfwkAUgibZYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af25c4ee-756d-4f5b-ddb9-e75cc957caf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find 20% of 500, I need to calculate 20% as a decimal (which is 0.20) and then multiply it by 500. \n",
            "\n",
            "Action: Calculator\n",
            "Action Input: 0.20 * 500\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 100.0\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: 100.0\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is 20% of 500?', 'output': '100.0'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Google Search Engine**\n",
        "\n",
        "Certain tools require API Keys. In this example, we use SERPER API.\n",
        "\n",
        "Create a new account and access your API KEY HERE:\n",
        "https://serpapi.com/users/welcome"
      ],
      "metadata": {
        "id": "krGZWUUENrYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Provide your SerpAPI key**"
      ],
      "metadata": {
        "id": "InQuuDE4OJuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your SerpAPI key to Colab Secrets with name 'SERPAPI_KEY' then run this cell\n",
        "\n",
        "serp_api_key = userdata.get('SERPAPI_KEY')\n",
        "os.environ[\"SERPAPI_API_KEY\"] = serp_api_key\n",
        "\n",
        "del serp_api_key"
      ],
      "metadata": {
        "id": "CdooaqibaoCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup tools\n",
        "\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "print(render_text_description(tools))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBq6JxMBWfcf",
        "outputId": "cba2ec7f-18ab-4228-cf8c-2bb1336ffc1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "Calculator(*args: Any, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Any - Useful for when you need to answer questions about math.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ReAct agent using the create_react_agent function\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        "    stop_sequence=True,\n",
        ")"
      ],
      "metadata": {
        "id": "1C-mq_v3XA_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor from the agent and tools\n",
        "\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "-CcbsYB3XA_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Which of them was built first - Eiffel Tower or Taj Mahal?\"\n",
        "    }\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDuhwKUg8rkQ",
        "outputId": "43352334-b747-423e-a8b1-dbb0b7ec0108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo determine which structure was built first, I need to look up the construction dates of both the Eiffel Tower and the Taj Mahal. \n",
            "\n",
            "Action: Search  \n",
            "Action Input: \"Eiffel Tower construction date\"  \n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mThe assembly of the Tower was a marvel of precision, as all chroniclers of the period agree. The construction work began in January 1887 and was finished on March 31, 1889.\u001b[0m\u001b[32;1m\u001b[1;3mI have found the construction date for the Eiffel Tower, which began in January 1887 and was completed in March 1889. Now, I need to find the construction date for the Taj Mahal.\n",
            "\n",
            "Action: Search  \n",
            "Action Input: \"Taj Mahal construction date\"  \n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m1632\u001b[0m\u001b[32;1m\u001b[1;3mI have found that the Taj Mahal's construction began in 1632 and was completed in 1648. Now I can compare the two dates.\n",
            "\n",
            "Final Answer: The Taj Mahal was built first, starting in 1632, while the Eiffel Tower was constructed later, beginning in 1887.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"What is the height of Eiffel Tower in meters? Divide the resultant by 2?\"\n",
        "    }\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jVE_OtG85qb",
        "outputId": "bc454487-cbf5-44b4-f29b-051e38689c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find the height of the Eiffel Tower, I need to recall or search for its height in meters. After that, I will divide that height by 2 to get the final answer. \n",
            "\n",
            "Action: Search  \n",
            "Action Input: \"height of Eiffel Tower in meters\"  \u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Eiffel Tower ‚Ä∫ Height ShareSend feedbackClose menu'}\u001b[0m\u001b[32;1m\u001b[1;3mThe height of the Eiffel Tower is approximately 330 meters, including antennas. Now, I will divide this height by 2.\n",
            "\n",
            "Action: Calculator  \n",
            "Action Input: 330 / 2  \u001b[0m\u001b[33;1m\u001b[1;3mAnswer: 165.0\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: 165.0 meters\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Python Agent**\n",
        "\n",
        "Sometimes, for complex calculations, rather than have an LLM generate the answer directly, it can be better to have the LLM generate code to calculate the answer, and then run that code to get the answer."
      ],
      "metadata": {
        "id": "NNWmOmTQMaIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Python REPL** is a powerful tool for interactive programming, making it easy to experiment with Python code and get immediate feedback.\n",
        "\n",
        "It allows you to enter Python code, evaluate it immediately, and see the results right away.\n",
        "\n",
        "Components of Python REPL:\n",
        "\n",
        "* **Read:** The REPL reads the input you provide. This can be a single line of code, a block of code, or even multiple commands in succession.\n",
        "\n",
        "* **Eval:** The input is evaluated (executed) by the Python interpreter. This means that the code you entered is processed, and any calculations or operations are performed.\n",
        "\n",
        "* **Print:** The results of the evaluation are printed to the screen. This allows you to see the output immediately after entering your code.\n",
        "\n",
        "* **Loop:** After printing the result, the REPL loops back to read the next input, allowing you to continue interacting with the interpreter."
      ],
      "metadata": {
        "id": "-VZEOcCfIyCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
        "from langchain_experimental.utilities import PythonREPL"
      ],
      "metadata": {
        "id": "iLzhCn1OMvWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python_repl = PythonREPL()"
      ],
      "metadata": {
        "id": "8ry-KmmOgWX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python_repl.run(\"print(1+1)\")"
      ],
      "metadata": {
        "id": "-RVX7eYLgZHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ca964485-4a3e-4813-c471-d3f7cc9b6aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tool to pass to an agent\n",
        "\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "repl_tool = Tool(\n",
        "    name=\"python_repl\",\n",
        "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
        "    func=python_repl.run,\n",
        ")"
      ],
      "metadata": {
        "id": "EX4HVYCUhaFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup tools\n",
        "\n",
        "tools = load_tools([], llm=llm) + [repl_tool, ]"
      ],
      "metadata": {
        "id": "Yt0BEPg2iOFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ReAct agent using the create_react_agent function\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        "    stop_sequence=True,\n",
        ")"
      ],
      "metadata": {
        "id": "IuTInPBmX7vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor from the agent and tools\n",
        "\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "vMNsziwPX7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1\n",
        "\n",
        "result = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Sort the following list ['Daisy', 'Elsa', 'Alan', 'Ben', 'Claire'] and print the result\"\n",
        "    }\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kWj-SABbOuM",
        "outputId": "eb7d5584-ed9b-4e9a-f458-3b31966a52f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to sort the given list of names in alphabetical order. I will use Python's built-in sorting functionality to achieve this. \n",
            "\n",
            "Action: python_repl  \n",
            "Action Input: `sorted(['Daisy', 'Elsa', 'Alan', 'Ben', 'Claire'])`  \u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mI need to check the output of the sorting operation to see the sorted list of names. \n",
            "\n",
            "Action: python_repl  \n",
            "Action Input: `print(sorted(['Daisy', 'Elsa', 'Alan', 'Ben', 'Claire']))`  \u001b[0m\u001b[36;1m\u001b[1;3m['Alan', 'Ben', 'Claire', 'Daisy', 'Elsa']\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
            "Final Answer: ['Alan', 'Ben', 'Claire', 'Daisy', 'Elsa']\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"Sort the following list ['Daisy', 'Elsa', 'Alan', 'Ben', 'Claire'] and print the result\",\n",
              " 'output': \"['Alan', 'Ben', 'Claire', 'Daisy', 'Elsa']\"}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2\n",
        "\n",
        "result = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"print(len('hello') + 5)\"\n",
        "    }\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2K8BySuYLy5",
        "outputId": "c9af6753-6d44-4b2f-dcf1-c4225d3748dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to calculate the length of the string 'hello' and then add 5 to that length. The length of 'hello' is 5, so I will perform the addition.\n",
            "\n",
            "Action: python_repl\n",
            "Action Input: print(len('hello') + 5)\u001b[0m\u001b[36;1m\u001b[1;3m10\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 10\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"print(len('hello') + 5)\", 'output': '10'}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Define your own tool**\n",
        "\n",
        "First we have to import the tool decorator which convert any function as tool that langchain can use."
      ],
      "metadata": {
        "id": "FdULvW4F_JEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "\n",
        "def timefunc(text: str) -> str:\n",
        "    dt_india = dt.datetime.utcnow() + dt.timedelta(hours=5, minutes=30)\n",
        "    return dt_india.strftime('%Y-%m-%d %H:%M:%S.%f')"
      ],
      "metadata": {
        "id": "yi0Whjm8zdlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tool to pass to an agent\n",
        "\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "timetool = Tool(\n",
        "    name=\"time_tool\",\n",
        "    description=\"\"\"Returns current date and time, use this for any \\\n",
        "    questions related to knowing current date and Indian time. \\\n",
        "    The input should always be an empty string, \\\n",
        "    and this function will always return current  \\\n",
        "    date and time.\"\"\",\n",
        "    func = timefunc,\n",
        ")"
      ],
      "metadata": {
        "id": "dWL8I-iizCxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([], llm=llm) + [timetool, ]\n",
        "tools"
      ],
      "metadata": {
        "id": "sPzWAPVTzt-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7681b318-ce53-400f-b2a4-e6ee4a9067fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='time_tool', description='Returns current date and time, use this for any     questions related to knowing current date and Indian time.     The input should always be an empty string,     and this function will always return current      date and time.', func=<function timefunc at 0x791fde1ea680>)]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ReAct agent using the create_react_agent function\n",
        "\n",
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt,\n",
        "    stop_sequence=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Oub9I8fBbm34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor from the agent and tools\n",
        "\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "l8KhuAmwbm35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"What is the current time?\"\n",
        "    }\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1QgV3r_bp_k",
        "outputId": "6e4446c5-a6c7-495a-9ac4-7468ce46b64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out the current date and time. \n",
            "Action: time_tool\n",
            "Action Input: \"\"\u001b[0m\u001b[36;1m\u001b[1;3m2024-10-30 13:30:11.609824\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The current time is 13:30:11 on October 30, 2024.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the current time?',\n",
              " 'output': 'The current time is 13:30:11 on October 30, 2024.'}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}